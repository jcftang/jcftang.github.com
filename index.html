
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Jimmy Tang</title>
  <meta name="author" content="Jimmy Tang">
  <meta name="Generator" content="Jekyll & Octopress (http://octopress.org)">

  
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jcftang.github.com/">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/octopress.min.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Jimmy Tang" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-8597777-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


   
  <link href="/octopress-favicon.png" rel="icon">
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Jimmy Tang</a></h1>
  
    <h2>Yet more random mutterings</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jcftang.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="/blog/categories">Categories</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
    










    <article >
      
  <header>
    <h1 class="entry-title">

<a href="/2012/11/04/there-is-light-on-the-otherside/">There Is Light on the Otherside</a>

</h1>

    
      <p class="meta">
        








  


<time datetime="2012-11-04T19:52:00+00:00" pubdate data-updated="true">Nov 4<span>th</span>, 2012</time>
        
         | <a href="/2012/11/04/there-is-light-on-the-otherside/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/11/04/there-is-light-on-the-otherside/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>Having spent the best part of my Sunday afternoon playing with ansible
just to learn and see what all the fuss is about, I was pleasantly
surprised with it.</p>

<p>I had installed <a href="https://github.com/ansible/ansible">ansible</a> on my OSX
laptop and <a href="https://github.com/ansible/vagrant-ansible">vagrant-ansible</a>
for my vagrant test environment.</p>

<p>The plan was to try and re-create my current ruby on rails development
and test virtual machine with vagrant. A secondary goal was to get it
to work with both Ubuntu Precise (LTS) and Scientific Linux 6.</p>

<p>My attempt at doing the above can be found at
<a href="https://github.com/jcftang/tchpc-vagrant/tree/ansible">tchpc-vagrant</a>
in the ansible branch. You will need ansible installed on your host
machine. You don&#8217;t need much installed in the target machine as ansible
is designed to login and execute commands as required, this is quite
refreshing. Compared to puppet and chef, if I were to roll this out
into production my overhead will be pretty low. This low overhead is
something that I really like as I don&#8217;t need to setup an infrastructure
just to run puppet.</p>

<p>In short I was able to learn how ansible is supposed to work (I think)
and build up enough configuration to start up a vagrant vm with what I
need for to do rails development in a matter of hours.</p>

<p>One thing that did occur to me was the lack of windows support, given
that ansible is designed to use ssh to carry out its activities, finding
stock windows machines which run ssh is pretty slim. This is one area
which puppet (perhaps chef too) is better at. It&#8217;s also one feature that
I would like as the vagrant vm&#8217;s that we&#8217;re using in work might be given
to windows users for testing and evaluation.</p>

<p>Going forward I think ansible will certainly be in my toolkit. There really is
a light on the otherside for mangement, deployment and orchestration.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/11/04/there-is-light-on-the-otherside/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    










    <article >
      
  <header>
    <h1 class="entry-title">

<a href="/2012/10/27/crowbar-for-deploying-systems/">Crowbar for Deploying Systems</a>

</h1>

    
      <p class="meta">
        








  


<time datetime="2012-10-27T20:07:00+01:00" pubdate data-updated="true">Oct 27<span>th</span>, 2012</time>
        
         | <a href="/2012/10/27/crowbar-for-deploying-systems/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/10/27/crowbar-for-deploying-systems/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>I&#8217;ve been eyeing <a href="https://github.com/dellcloudedge/crowbar">crowbar</a>
recently, it looks pretty useful and interesting for deploying servers
and applications. I haven&#8217;t seen much if at all any documentation out
there which suggests that people in the digital preservation and archiving
fields are implementing systems at scale, I&#8217;m under the impression that
most systems/sites are building systems up one piece at a time without
much automation.</p>

<p>It seems to use <a href="http://www.opscode.com/chef/">chef</a> in the backend for
all the automation. I&#8217;ve been relearning <a href="http://puppetlabs.com/">puppet</a>
recently so that I can have reproducible environments with
<a href="http://vagrantup.com/">Vagrant</a>.</p>

<p>There might be an advantage to learn and port all the existing modules
that I have already created and configured to chef instead of puppet. If
I did move to a chef automation in my vagrant environments then a few
years from now when we go to full production we might be able to deploy
the whole system from bare metal relatively quickly and repeatably.</p>

<p>Automating the deployments will mean that we will have documentation
on the infrastructure itself. Either which way there is still a need
to automate the fedora-commons, SOLR, mysql and postgres deployments at
some point.</p>

<p>After all this thinking and pondering, I&#8217;m still using puppet. There&#8217;s
still the likes of ansible, cfengine, bcfg2 and juju. There is a never
ending supply of these tools.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/10/27/crowbar-for-deploying-systems/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    



  








    <article class="linklog">
      
  <header>
    <h1 class="entry-title">

<a href="http://ceph.com/releases/v0-53-released/">Ceph V0.53 RELEASED</a>
<span class='linklog-marker'>&rarr;</span>
</h1>

    
      <p class="meta">
        








  


<time datetime="2012-10-23T15:08:00+01:00" pubdate data-updated="true">Oct 23<span>rd</span>, 2012</time>
        
         | <a href="/2012/10/23/ceph-v0-dot-53-released/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/10/23/ceph-v0-dot-53-released/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>There&#8217;s a new release of Ceph, I hope that they release a stable soon so we can
do further evaluations of the Ceph storage
system. A few of my work colleagues are going to the <a href="http://www.inktank.com/news-events/event/ceph-workshops-amsterdam/">Ceph
workshop</a>
next week.</p>

<p>I&#8217;m wondering if anyone has taken the CRUSH algorithm and used it in other
domains.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/10/23/ceph-v0-dot-53-released/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    



  








    <article class="linklog">
      
  <header>
    <h1 class="entry-title">

<a href="http://yourmediashelf.com/hydracamp/">Hydracamp 2012 - Penn State</a>
<span class='linklog-marker'>&rarr;</span>
</h1>

    
      <p class="meta">
        








  


<time datetime="2012-10-13T07:34:00+01:00" pubdate data-updated="true">Oct 13<span>th</span>, 2012</time>
        
         | <a href="/2012/10/13/hydracamp-2012-penn-state/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/10/13/hydracamp-2012-penn-state/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>What do you do when you need a crash course on RoR, Hydra and frameworks for
digital preservation and archiving? You go to Hydracamp!</p>

<p>The syllabus was</p>

<ul>
<li>Day 1 - Rails, CRUD, TDD and Git</li>
<li>Day 2 - Collaborative development with Stories, Tickets, TDD and Git</li>
<li>Day 3 - Hydra, Fedora, XML and RDF (ActiveFedora and OM)</li>
<li>Day 4 - SOLR and Blacklight</li>
<li>Day 5 - Hydra-head, Hydra Access Controls</li>
</ul>


<p>Most of the training sessions were hands on from day 1 which was
refreshing, as it was hands on I getting the most out of the training
session. It would have been better if I had known more ruby to move
along some of the exercises more effectively.</p>

<p>To give an overview of what we had done (between ~30 people), we created
a ruby on rails application titled &#8220;Twitter for Zombies&#8221;. With this small
application everybody was frantically committing, pulling, merging and
pushing code. It was highly informative and a good learning experience
to see how fast things could move.</p>

<p>The training session also included a crash course into what Fedora and
SOLR does and how Hydra interacts with these components. The third and
fourth days were the most interesting as it showed how someone might
convert from a typical RoR application into an application which uses
Fedora as the persistance layer. The last day was really just a wrap up
and Q&amp;A session.</p>

<p>You could take a look at the <a href="https://github.com/projecthydra">github</a>
account for Project Hydra and have a peek at the hydracamp repo.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/10/13/hydracamp-2012-penn-state/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    










    <article >
      
  <header>
    <h1 class="entry-title">

<a href="/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/">Digital Preservation and Archiving Is a HPC Problem?</a>

</h1>

    
      <p class="meta">
        








  


<time datetime="2012-10-07T13:42:00+01:00" pubdate data-updated="true">Oct 7<span>th</span>, 2012</time>
        
         | <a href="/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>I shall be going to SC2012 next month, I plan on hitting a few of the
storage vendors for possible collaborations and flagging to them that
we&#8217;re on the look out for storage systems. One of the first
observation that the reader will note is &#8220;where is that link between
HPC and Digital Preservation and Archiving&#8221;. It&#8217;s probably not obvious
to most people, one of the big problems in the area of preservation
and archiving is the the amount of data involved and the varied types
of data. This is not taking into account of the issues with data
access patterns.</p>

<p>Given that a preservation and archiving project will want to provide a
trusted system, the system will want to read out every single byte
that was put in to verify that the data is correct at somepoint
(usually with some form of hashing).</p>

<p>Reading data out and checking that it&#8217;s correct serially probably
isn&#8217;t the smartest solution. Nor is copying the data into 2-3
locations (where each site is maintaining 2-3 copies for backups and
redundancy). The current and seemingly most popular solutions is to
dump the data to a few offsite locations (such as S3 or SWIFT)
compatible storage systems, then just hoping for the best that if
anyone of the sites is down or corrupted there site can be restored
from the other sites or from a backup. I need to delve deeper into the
storage and data-distribution strategies that some of the bigger
projects are taking. There has to be a smarter way of storing and
preserving data without having to make copies of things.</p>

<p>I&#8217;ve often wondered how projects manage to copy/move data across
storage providers in a reasonable amount of time without needing to
wheel a few racks of disks around. It would also be interesting to see
the error rates of these systems and how often errors are
corrected. If they are corrected what is the computational cost of
doing this.</p>

<p>If you have a multi-terabyte archive the problem isn&#8217;t too bad, the
more typical case these days might be in the order of the low hundreds
of terabytes. I could only imagine what lager scale sites must deal
with. I&#8217;m still not a fan of moving a problem from a local site to a
remote site as it often shows that there is a lack of understanding to
the problem. Storage in the preservation and archiving domain will
probably turn into an IO and compute intensive operation at some
point, especially if you want to do something with the data.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    



  








    <article class="linklog">
      
  <header>
    <h1 class="entry-title">

<a href="https://github.com/jcftang/slurm-bank">SLURM-Bank That Big Script for Banking in SLURM</a>
<span class='linklog-marker'>&rarr;</span>
</h1>

    
      <p class="meta">
        








  


<time datetime="2012-09-29T19:52:00+01:00" pubdate data-updated="true">Sep 29<span>th</span>, 2012</time>
        
         | <a href="/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>A co-worker of mine (Paddy Doyle) had originally hacked at a perl script
for reporting balances from SLURM&#8217;s accounting system a year or two ago
and he had figured out that it might be possible to do some minimalistic
&#8216;configuration&#8217; and scripting to get a system that&#8217;s very basic but
functional.</p>

<p>It was just one of those things that funding agencies wanted to justify
how the system was being used, GOLD was clunky and obtrusive and
complicated for what we wanted. Most of all we liked SLURM but not GOLD
and Maui which was needed to get full accounting and banking (most of
the features weren&#8217;t used).</p>

<p>Being good and lazy engineers we got excited with the prospect of having
the option of replacing SLURM, Maui and GOLD with just plain old SLURM
we set out to write down the workflows for what we wanted to do and what
the user and funding agencies actually wanted. With those ideas in mind
we set out to implement as much as we could and needed in just plain
old sh/bash scripting with a splash of perl. Replacing two components
with one meant that we would have less work to do in the long run ;)</p>

<p>After a whole year of running with these scripts and just putting it
online, I&#8217;ve noticed that there may be a few sites out there that might
be using our scripts and workflows. It would be nice to find out how
many people are using our implementation of a banking system in SLURM
and if it&#8217;s driven by sysadmins looking to account for usage or is it
funding agencies looking for justification of the usage of a system.</p>

<p>I was going to be at the SLURM User Group Meeting 2012 to give a
short talk on our experiences with the SLURM-Bank scripts and workflow,
but sadly I have to be in the US during this meeting and my colleague
&#8220;Paddy Doyle&#8221; will there instead of me.  I would have liked to go and chat
with the developers of SLURM to push for more advanced banking/accounting
facilities in SLURM itself. Visiting BSC again would have been fun.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    



  








    <article class="linklog">
      
  <header>
    <h1 class="entry-title">

<a href="http://ceph.com/releases/v0-52-released/">Ceph V0.52 RELEASED</a>
<span class='linklog-marker'>&rarr;</span>
</h1>

    
      <p class="meta">
        








  


<time datetime="2012-09-28T15:52:00+01:00" pubdate data-updated="true">Sep 28<span>th</span>, 2012</time>
        
         | <a href="/2012/09/28/ceph-v0-dot-52-released/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/09/28/ceph-v0-dot-52-released/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>The latest development branch of Ceph is out with some rather nice
looking features, what&#8217;s probably the most useful are the RPM builds
for those that run RHEL6 like systems.</p>

<p>Still no real sight of backported kernel modules :P Also some of the
guys in work here just deployed a ~200tb Ceph installation which I&#8217;ve
access to a 10tb RBD for doing backups on.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/09/28/ceph-v0-dot-52-released/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    










    <article >
      
  <header>
    <h1 class="entry-title">

<a href="/2012/09/23/a-poor-mans-nas-device-with-ceph/">A Poor Man&#8217;s NAS Device With Ceph</a>

</h1>

    
      <p class="meta">
        








  


<time datetime="2012-09-23T08:59:00+01:00" pubdate data-updated="true">Sep 23<span>rd</span>, 2012</time>
        
         | <a href="/2012/09/23/a-poor-mans-nas-device-with-ceph/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/09/23/a-poor-mans-nas-device-with-ceph/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>Given that I have a number of old 64bit capable desktop machines and a
collection of hard drives at home, I could have run
<a href="https://tahoe-lafs.org/trac/tahoe-lafs">Tahoe-LAFS</a> like I do in work
for backup purposes. In fact Tahoe works quite well for the
technically capable user.</p>

<p>Recently I&#8217;ve decided that I need a more central location at home to
store my photo collection (I love to take photos with my Canon DSLR
and Panasonic LX5). Traditionally I would have just fired up
<a href="http://git-annex.branchable.com/">git-annex</a> to track the data and
then setup a number of remotes to store the data, where one of them
might be Tahoe-LAFS and the rest might be portable hard drives, remote
machines etc&#8230;</p>

<p>I could have gone with any number of distributed storage solutions
such as <a href="http://www.gluster.org/">GlusterFS</a>,
<a href="http://www.irods.org">iRODS</a>,
<a href="http://xrootd.slac.stanford.edu/">xrootd</a>,
<a href="http://wiki.lustre.org/index.php/Main_Page">Lustre</a> or
<a href="http://www.xtreemfs.org/">xtreemfs</a>. I&#8217;ve worked with some of these
systems in production and toyed with others. Since this is for a home
system I can pick what I want and change it at will.</p>

<p>I probably have 2-3tb&#8217;s of data to archive and store, I also want easy
access to my data so NFS or CIFS exports are required. It wouldn&#8217;t be
unfeasible to acquire a few 2 or 3 terabyte drives for my old desktop
machine which would effectively provide me with a 2 or 3 terabyte
replicated data store. Given the amount of toying around and learning
about Ceph in my spare time I would expect that Ceph would provide me
with a pretty good &#8220;backend&#8221; system for storing my files and the
option of &#8220;migrating my data from one machine to another machine&#8221; by
adding and removing OSD&#8217;s. The handiest feature for me will be the
capability of expanding and shrinking the system as I need.</p>

<p>There probably aren&#8217;t many people who would want to setup something
like this for a home system, but it is an alternative to the usual
RAID or LVM setup.</p>

<p>Here&#8217;s my proposed setup which I&#8217;m going to setup in the next few
spare weekends that I will have.</p>

<p><img class="" src="/downloads/images/ceph-home.png"></p>

<p>It would be great if Ceph offered some of of parity/erasure coding
instead of plain replication. I&#8217;m greedy and I want to maximise my
disks that I have, I wonder how low I can go on hardware with the Ceph
software.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/09/23/a-poor-mans-nas-device-with-ceph/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    



  








    <article class="linklog">
      
  <header>
    <h1 class="entry-title">

<a href="http://ceph.com/releases/v0-48-2-argonaut-stable-update-released/">Ceph V0.48.2 ARGONAUT RELEASED</a>
<span class='linklog-marker'>&rarr;</span>
</h1>

    
      <p class="meta">
        








  


<time datetime="2012-09-21T10:38:00+01:00" pubdate data-updated="true">Sep 21<span>st</span>, 2012</time>
        
         | <a href="/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>There&#8217;s a new stable release of Ceph Argonaut, I seem to be having better
luck with playing with the development releases of Ceph.</p>

<p>Oh how I wish that there was a backport of the kernel ceph and rbd drivers
for RHEL6, I have a dodgy repo and some reverted commits that one of
the guys in work told me about. It seems to run but it isn&#8217;t great,
it can be found at <a href="https://github.com/jcftang/ceph-client-standalone">https://github.com/jcftang/ceph-client-standalone</a>.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
    










    <article >
      
  <header>
    <h1 class="entry-title">

<a href="/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/">Going From Replicating Across OSD&#8217;s to Replicating Across Hosts in a Ceph Cluster</a>

</h1>

    
      <p class="meta">
        








  


<time datetime="2012-09-06T21:44:00+01:00" pubdate data-updated="true">Sep 6<span>th</span>, 2012</time>
        
         | <a href="/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/#disqus_thread">Comments</a>
        
         &bull; <a rel="bookmark" href="/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/">Permalink</a>
      </p>
    
  </header>

<div class="entry-content"><p>Having learnt how to remove and add monitor&#8217;s, meta-data and data servers (mon&#8217;s, mds&#8217;s
and osd&#8217;s) for my small two node Ceph cluster. I want to say that it wasn&#8217;t too hard to
do, the ceph website does have documentation for this.</p>

<p>As the default CRUSH map replicates across OSD&#8217;s I wanted to try replicating data across
hosts just to see what would happen. In a real world scenario I would probably treat
individual hosts in a rack as a failure unit and if I had more than one rack of storage,
I would want to treat each rack as the minimum unit.</p>

<p>One of the coolest features of ceph is that it allows me to play with different mappings
and configurations of where my data gets allocated. There aren&#8217;t many (if any) storage
systems that I know of which provides this type of capability.</p>

<p>So the steps that I went through to get to what I wanted&#8230;</p>

<p>First I had to dump the CRUSH map from my cluster of two nodes and three (very unbalanced OSD&#8217;s so I can play with the weights).</p>

<pre><code>ceph osd getcrushmap -o /tmp/mycrushmap
</code></pre>

<p>The CRUSH map that is created is a binary file it must be decoded to plain text before
you can edit it.</p>

<pre><code>crushtool -d /tmp/mycrushmap &gt; /tmp/mycrushmap.txt
</code></pre>

<p>Here&#8217;s the map that is decoded from the binary file</p>

<pre><code># begin crush map

# devices
device 0 osd.0
device 1 osd.1
device 2 osd.2

# types
type 0 osd
type 1 host
type 2 rack
type 3 row
type 4 room
type 5 datacenter
type 6 pool

# buckets
host x.y.z.194 {
        id -2           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item osd.1 weight 1.000
        item osd.0 weight 1.000
}
host x.y.z.138 {
        id -4           # do not change unnecessarily
        # weight 1.000
        alg straw
        hash 0  # rjenkins1
        item osd.2 weight 1.000
}
rack rack-1 {
        id -3           # do not change unnecessarily
        # weight 3.000
        alg straw
        hash 0  # rjenkins1
        item x.y.z.194 weight 2.000
        item x.y.z.138 weight 1.000
}
pool default {
        id -1           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item rack-1 weight 2.000
}

# rules
rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule metadata {
        ruleset 1
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule rbd {
        ruleset 2
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}

# end crush map
</code></pre>

<p>The relevant chunks of the config that I&#8217;m interested in is the <strong>rule NAME {}</strong> blocks.
As I&#8217;m interested in making my data, meta-data and probably my rbd rule replicate across hosts, I naturally made the rule look like this</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step emit
}
</code></pre>

<p>The above change is apparently incorrect as the last step before the <em>step emit</em> needs
to be a device of some sort. I had found this out after posting the ceph-devel mailing
list. There were two proposed solutions (thanks to Greg from inktank), the first
proposed rule was</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step choose firstn 1 osd
        step emit
}
</code></pre>

<p>Which selects <em>n</em> hosts then the first osd from each host, but it can&#8217;t deal with an entire hosts failed OSD&#8217;s. The second proposed rule was</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step chooseleaf firstn 0 type host
        step emit
}
</code></pre>

<p>The above rule will select <em>n</em> hosts and an OSD from the host. It&#8217;s pretty obvious that
the second rule is the one that I want. I would expect that if I had more machines in
racks and rows I could probably just replace host with rack, row or even data-center.</p>

<p>With the second proposed rule, I made the changes to <em>mycrushmap.txt</em>. Once the changes
are made, I had to compile the map into a binary format that the ceph cluster
understands, this can be done by</p>

<pre><code>crushtool -c /tmp/mycrushmap.txt -o /tmp/mycrushmap.new
</code></pre>

<p>Once the map is compiled it must then be applied to the cluster</p>

<pre><code>ceph osd setcrushmap -i /tmp/mycrushmap.new
</code></pre>

<p>The above is documented on the ceph website. Once I applied the new CRUSH map I ran a <em>ceph -w</em> to see that
the system had detected the changes and it then started to move data around on its own. I&#8217;ll need to play
with pulling out the network cable or SATA cables to see how the system behaves from me causing catastrophic
failures in the test system.</p>

<p>I&#8217;m pretty sure I took the long way around to making the changes, there must be a more dynamic way of
changing the system.</p>

<p>To recap and review the above operation, it&#8217;s again no harder than my reference system that I know, which is
GPFS. GPFS doesn&#8217;t allow me to do what ceph allows me to do. I would however like to see some more visible
documentation relating to the CRUSH configuration parameters and tuneables.</p>

<p>So far this has been a distraction from my main day job, but this will certainly help
with the project that I am working on in the long run.</p>
</div>

  <footer>
    
    <p><a class="comments-link" href="/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/#disqus_thread">View comments &raquo;</a></p>
    
    
  </footer>


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/archives/">Blog Archives</a>
    
  </div>
</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>This is more of a technical blog of what I want to rant about
  separate from my <a href="http://www.sgenomics.org/~jtang/">personal blog</a>.</p>
</section>

<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2012/11/04/there-is-light-on-the-otherside/">There is light on the otherside</a>
      </li>
    
      <li class="post">
        <a href="/2012/10/27/crowbar-for-deploying-systems/">Crowbar for deploying systems</a>
      </li>
    
      <li class="post">
        <a href="/2012/10/23/ceph-v0-dot-53-released/">Ceph V0.53 RELEASED</a>
      </li>
    
      <li class="post">
        <a href="/2012/10/13/hydracamp-2012-penn-state/">Hydracamp 2012 - Penn State</a>
      </li>
    
      <li class="post">
        <a href="/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/">Digital Preservation and Archiving is a HPC problem?</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>On GitHub</h1>
  <ul id="gh_repos" data-user="jcftang" data-count="0" data-skip="true">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a class="github-follow" href="https://github.com/jcftang">Follow @jcftang</a>
  
</section>



<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets" data-user="jcftang" data-count="4" data-replies="false">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
    <a href="//twitter.com/jcftang" class="twitter-follow-button" data-show-count="false">Follow @jcftang</a>
  
</section>







  <a href="https://plus.google.com/115375964029787125148?rel=author">
    <img src="https://ssl.gstatic.com/images/icons/gplus-32.png" alt="Google Plus icon">
  </a>




  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Jimmy Tang -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jcftang';
			var disqus_developer = '0';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>






</body>
</html>
