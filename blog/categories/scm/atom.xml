<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: scm | Jimmy Tang]]></title>
  <link href="http://jcftang.github.com/blog/categories/scm/atom.xml" rel="self"/>
  <link href="http://jcftang.github.com/"/>
  <updated>2012-05-31T08:29:18+01:00</updated>
  <id>http://jcftang.github.com/</id>
  <author>
    <name><![CDATA[Jimmy Tang]]></name>
    <email><![CDATA[jcftang@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      




<title type="html"><![CDATA[Is JAVA really the only game in town for building Digital Preservation Systems?]]></title>
<link href="http://jcftang.github.com/blog/2012/05/16/is-java-really-the-only-game-in-town-for-building-digital-preservation-systems/"/>
<updated>2012-05-16T18:24:00+01:00</updated>
<id>http://jcftang.github.com/blog/2012/05/16/is-java-really-the-only-game-in-town-for-building-digital-preservation-systems</id>

      <content type="html"><![CDATA[<p>In the world of digital preservation and repositories it seems that
there is primarily fedora-commons, dspace, eprints and one or two
other solutions out there for building up digital preservation
systems. The one that really stands out as a framework and toolkit for
building bigger and more complex systems is fedora-commons.</p>

<p>It also happens to be written in JAVA and is a fairly big and complex
system which implements best-practices for storing digital objects
with the sole purpose of preservation. In one of the projects that I
have been working with some interns at work; we have treated
fedora-commons as just storage system where we interface to the
preservation repository via the available REST api.</p>

<p>By using the API it was possible to use node.js to implement the
servers which contained all the business logic. Project Hydra does
something similar or rather we are doing something similar to Project
Hydra, by accident much to my suprise. Hydra uses Ruby on Rails for
its middleware implementation, there doesn't seem to be much JAVA
there either.</p>

<p>I get the feeling that this decoupled approach with REST servers and
clients to be pretty attractive to anyone who wishes to implement
these types systems. It is interesting to see that the applications
aren't being written in JAVA. At least that is what I can see with the
projects that use Hydra (which is sort of the point). Maybe good
enough practice is fine for most use cases.</p>

<p>This makes me wonder how many digital preservation projects out there
really use 100% JAVA up to delivery to the client? How many projects
out there are really just mashups of different types of technology
(well planned mashups). Is it because of "best practice" for
implementing enterprise applications that JAVA gets so much focus and
attention?</p>

<p><a rel="bookmark" href="http://jcftang.github.com/blog/2012/05/16/is-java-really-the-only-game-in-town-for-building-digital-preservation-systems/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[git-subtree is now in mainline git]]></title>
<link href="http://jcftang.github.com/blog/2012/05/02/git-subtree-is-now-in-mainline-git/"/>
<updated>2012-05-02T09:27:00+01:00</updated>
<id>http://jcftang.github.com/blog/2012/05/02/git-subtree-is-now-in-mainline-git</id>

      <content type="html"><![CDATA[<p>It seems that <a href="git://github.com/apenwarr/git-subtree.git">git-subtree</a>
has been merged into the mainline git project. <em>git-subtree</em> is one of
those really useful wrappers for manipulating git repositories if you
are an integrator or don't really like git-submodule. It certainly is
a nicer alternative to git-submodule. There is less chance of the
person cloning a git-subtree repository messing up the checkout because
they forgot to initialise the submodules. There is also the added
advantage of not needing to fiddle around scripting up the git-archive
commands for exporting the source tree for a release if you use
git-subtree; actually git-subtree is just plain useful.</p>

<p><a rel="bookmark" href="http://jcftang.github.com/blog/2012/05/02/git-subtree-is-now-in-mainline-git/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Prototyping and testing systems]]></title>
<link href="http://jcftang.github.com/blog/2012/04/09/prototyping-and-testing-systems/"/>
<updated>2012-04-09T11:12:00+01:00</updated>
<id>http://jcftang.github.com/blog/2012/04/09/prototyping-and-testing-systems</id>

      <content type="html"><![CDATA[<p>One of the issues with with dogfooding your own projects to accelerate
development might be the lack of control and feedback from the
specifications and requirements process. To try and mitigate this
effect, automated testing should be done, that is specification,
feature and behavioural testing. Call it what you will, but the basic
idea is to get a common understanding between the stakeholder, project
owner and developer to understand what is being built and to write
automated tests collectively to ensure that it is being
delivered. This might be a narrow view of the whole area, but I'm just
taking what works for me and using it to deliver the project.</p>

<p>There are <em>many</em> specification/feature/behavioural testing tools out
there for almost language that you can think of, so use what works for
you and your team. The testing process not only ensures that the
prototype is working the way that you intend, but it is also a process
where documentation can also be written at the sametime. This
documentation could be used as an initial proposal to the stakeholder
to put forward what you think they want if there are no clear
specifications or requirements in place.</p>

<p>The interns and I have been working on a small prototype system
for a bigger project and the benefits of writing tests are beginning
to show. It has become apparent to the interns that have been working
on this project that <em>testing is a good thing</em>, especially if it can
be automated. We're not quite doing TDD or BDD, but it's something
that is in between, we're getting there with a tiered set of tests.</p>

<p>We're finding that (probably) about 50% of the time of the team is
spent on refactoring, writing tests and documentation. Testing
combined with the automated builder/tester, the team is writing code
smarter and better instead of just churning out masses of code which
isn't well tested or documented. Given the choice and based on
experience I would prefer to have code that is tested and
documentated, rather than lots of cool half-working and half-tested
features.</p>

<p>The testing process has been a fantastic way for me to steer the
interns, given how little expertise I have with javascript. The tests
let me learn how the interns have been putting the prototype together,
but it also lets me fuzz up the tests to make sure things are working
and to also write new tests to communicate what I think is needed when
appropriate. We've somewhat combined minimal QA into the development
and testing process.</p>

<p>In the end we hope to have a functional prototype system which does
one thing (one set of workflows) well, have lots of documentation,
have tests to back it up and prove that it works. While having an
implementation is great for the potential stakeholder, having
documentation and tests puts us in an even stronger position.<p><a rel="bookmark" href="http://jcftang.github.com/blog/2012/04/09/prototyping-and-testing-systems/">&infin; Permalink</a></p></p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Gitbuilder aggregator &rarr;]]></title>
<link href="https://github.com/jcftang/gitbuilder/tree/develop/contrib/gitbuilder-ajax"/>
<updated>2012-04-01T11:05:00+01:00</updated>
<id>http://jcftang.github.com/blog/2012/04/01/gitbuilder-aggregator</id>

      <content type="html"><![CDATA[<p>We use git and <a href="https://github.com/apenwarr/gitbuilder">gitbuilder</a> in
work for a large number of projects, we also try and test things as
much as we can. I first noticed that someone had written an aggregator
for gitbuilder at <a href="http://ceph.newdream.net/gitbuilder.cgi">ceph
gitbuilders</a>, this seemed
like a great idea (and it is) except the aggregator at the time didn't
quite work very fast and needed some ajax magic.</p>

<p>I had asked for a copy of the aggregator script from the ceph
developers, this was really just a perl hack as they said, but it
works. Since we had some students doing an internship here to learn
new things, I got one of the interns to write an ajax'd up version of
the aggregator.</p>

<p>After a few weeks worth of usage and minor changes, it's a bit more
ready to share with everyone, the ajax'd up version of the aggregator
can be found at my
<a href="https://github.com/jcftang/gitbuilder/tree/develop/contrib/gitbuilder-ajax">github</a>
account in the develop branch. For fun I updated the main gitbuilder
cgi scripts to use twitter bootstrap and add a link to the errcache
file that gitbuilder generates.</p>

<p>We found that with large builds the logs would just swamp out the
errors and warnings and having access to the errcache helped a lot in
narrowing down where to look for problems, hence the linking to the
errcache.</p>

<p>At somepoint it might be worth re-implementing the gitbuilder scripts
in a single language in a generic way such that it works with other
DVCS's that have the bisect feature.<p><a rel="bookmark" href="http://jcftang.github.com/blog/2012/04/01/gitbuilder-aggregator/">&infin; Permalink</a></p></p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Dogfooding your own project to accelerate development]]></title>
<link href="http://jcftang.github.com/blog/2012/03/15/dogfooding-your-own-project-to-accelerate-development/"/>
<updated>2012-03-15T19:31:00+00:00</updated>
<id>http://jcftang.github.com/blog/2012/03/15/dogfooding-your-own-project-to-accelerate-development</id>

      <content type="html"><![CDATA[<p>Should you dogfood your own project that you are developing? The
answer is probably yes, especially if you have no clear cut
requirements from the stakeholder in a project with a greenfield for
development. There is a lot to be said about having a working
implementation that can be presented and refined.</p>

<p>Sometimes the project that you are working on won't have clear
requirements for implementation, so you should probably take basic
assumed cases and run with it. Starting early to see what works and
what doesn't work is a pragmatic approach which the waterfall crowd
might not like. But hey, an implementation speaks for itself.</p>

<p>If you don't use what you develop, then it is very hard to relate to
the customer/end-user in the long run. On the note of dogfooding your
own work, sometimes best-practice might cost too much in terms of time
and money, sometimes good-enough practice might just be enough to
deliver a functioning product.</p>

<p>Accelerating development by dogfooding your own work and using
good-enough practices should increase throughput of development, but
not necessarily quality. Again in a greenfield project where there
aren't many requirements due to the schedule, it's worth taking this
approach until hard requirements get delivered.</p>

<p><a rel="bookmark" href="http://jcftang.github.com/blog/2012/03/15/dogfooding-your-own-project-to-accelerate-development/">&infin; Permalink</a></p>

]]></content>
    </entry>
  
</feed>

