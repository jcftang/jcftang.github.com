<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Jimmy Tang]]></title>
  <link href="http://jcftang.github.com/atom.xml" rel="self"/>
  <link href="http://jcftang.github.com/"/>
  <updated>2013-01-26T11:08:13+00:00</updated>
  <id>http://jcftang.github.com/</id>
  <author>
    <name><![CDATA[Jimmy Tang]]></name>
    <email><![CDATA[jcftang@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      




<title type="html"><![CDATA[Deploying our hydra-head with jruby]]></title>
<link href="http://jcftang.github.com/2013/01/22/deploying-our-hydra-head-with-jruby/"/>
<updated>2013-01-22T19:49:02+00:00</updated>
<id>http://jcftang.github.com/2013/01/22/deploying-our-hydra-head-with-jruby</id>
<category term="dri" /><category term="java" /><category term="linux" /><category term="preservation" /><category term="ruby" />

      <content type="html"><![CDATA[<p>We&#39;ve been ramping up our development work on the project that I have been on
in the last month or so. One of the issues that we&#39;ve come across is the not
so good XML validation and parsing libraries that are available in the ruby
world compared to the java world.</p>

<p>So as an exercise I decided to see if I could make our prototype work
with jruby with the view of doing a test deployment on tomcat or some
other application server. One of the motivating reason for doing this
is to get access to the java based XML libraries for validation and
processing. It also means that if I can deploy to the same Tomcat server
where I&#39;m running SOLR and Fedora-Commons then it means I&#39;m saving myself
a chunk of work setting up and maintaining <em>mod_passenger</em>.</p>

<p>In short what I ended up doing was make sqlite3 as being dependent on
the ruby platform and creating a block for jruby. So here&#39;s the relevant
snippet from my <em>Gemfile</em></p>

<figure class='code'><div class='highlight'><table><td class='line-numbers' aria-hidden='true'><pre><div data-line='1' class='line-number'></div><div data-line='2' class='line-number'></div><div data-line='3' class='line-number'></div><div data-line='4' class='line-number'></div><div data-line='5' class='line-number'></div><div data-line='6' class='line-number'></div><div data-line='7' class='line-number'></div><div data-line='8' class='line-number'></div><div data-line='9' class='line-number'></div><div data-line='10' class='line-number'></div><div data-line='11' class='line-number'></div><div data-line='12' class='line-number'></div><div data-line='13' class='line-number'></div><div data-line='14' class='line-number'></div><div data-line='15' class='line-number'></div><div data-line='16' class='line-number'></div><div data-line='17' class='line-number'></div><div data-line='18' class='line-number'></div></pre></td><td class='main  ruby'><pre><div class='line'><span class="n">gem</span> <span class="s1">&#39;sqlite3&#39;</span><span class="p">,</span> <span class="ss">:platforms</span> <span class="o">=&gt;</span> <span class="ss">:ruby</span>
</div><div class='line'> </div><div class='line'><span class="n">platforms</span> <span class="ss">:jruby</span> <span class="k">do</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;jruby-openssl&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;activerecord-jdbcsqlite3-adapter&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;jruby-lint&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;warbler&#39;</span>
</div><div class='line'> </div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;actionmailer&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;actionpack&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;activerecord&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;activerecord-jdbc-adapter&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;activeresource&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;activesupport&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;jdbc-mysql&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;rack&#39;</span>
</div><div class='line'>  <span class="n">gem</span> <span class="s1">&#39;rake&#39;</span>
</div><div class='line'><span class="k">end</span>
</div></pre></td></tr></table></div></figure>

<p>What I found was that jruby behaves oddly when I&#39;m behind a proxy, it
seems to blindly take my system proxy settings on my mac, so I had to
work around it.</p>

<p>Nokogiri seems to be subtly different when deployed with jruby and thus
it breaks a bunch of things, which is funny as this was the main reason
to testing out jruby so that we can access the java based XML libraries.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Making the jump and migrating my archlinux machines to use btrfs]]></title>
<link href="http://jcftang.github.com/2013/01/02/making-the-jump-and-migrating-my-archlinux-machines-to-use-btrfs/"/>
<updated>2013-01-02T15:18:00+00:00</updated>
<id>http://jcftang.github.com/2013/01/02/making-the-jump-and-migrating-my-archlinux-machines-to-use-btrfs</id>
<category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>Having a few days of time off from work I&#39;ve committed to migrating my
archlinux based laptops to using btrfs. I&#39;ve to date been just using
ext4 and nilfs2 (on an SD card) on my eeepc and plain old ext4 on the
bigger laptop.</p>

<p>The main motivation was that the two devices were pretty outdated and
I felt lucky with doing a major upgrade (replaced sysvinit with systemd
as recommended by the archlinux people)</p>

<p>I didn&#39;t want to reinstall my machines so I took the route of converting
the existing ext4 partitions to btrfs. I left my <em>/boot</em> partition as
ext2 for safety. Prior to converting to btrfs I had upgraded the two
laptops to using <a href="https://wiki.archlinux.org/index.php/Grub2">grub2</a>
first. I then proceeded to boot up my laptops with the
archlinux installer image via a usb key. Then just followed the
<a href="https://wiki.archlinux.org/index.php/Btrfs">btrfs</a> documentation at
the archlinux wiki.</p>

<p>The process went more smoothly than I had anticipated, I didn&#39;t run into
any major stumbling blocks, that said I did have to free up some space
for the migration to occur.</p>

<p>Once the systems were back up and running I enabled compression on btrfs
and defragged the systems</p>
<div class="highlight"><pre><code class="text">find / -xdev -type f -print -exec btrfs filesystem defrag &#39;{}&#39; \;
</code></pre></div>
<p>This compression feature made a huge difference on the space limited
eeepc, the compression feature reclaimed about 10% of the space on the
system. It&#39;s a shame that the RHEL based distros aren&#39;t quite supporting
btrfs yet there are quite a few nice features there that are very
attractive for pro-consumers and the enterprise. RHEL7 will have btrfs,
hopefully there will be backports to RHEL6.</p>

<p>Performance wise I haven&#39;t used the system in anger yet, so time will
tell if I&#39;m happy with btrfs or not.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Supercomputing 2012 and the arms race to exascale]]></title>
<link href="http://jcftang.github.com/2012/11/16/supercomputing-2012-and-the-arms-race-to-exascale/"/>
<updated>2012-11-16T06:30:00+00:00</updated>
<id>http://jcftang.github.com/2012/11/16/supercomputing-2012-and-the-arms-race-to-exascale</id>
<category term="hpc" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>It was clear at this year&#39;s supercomputing conference that there wasn&#39;t
as much excitement as previous years. There wasn&#39;t much surprise as
nothing too revolutionary and radical was announced. In the past when
Bluegene/L and P arrived after the earth simulator there was an arms race
to being number 1 in the top500 list.  Even things like GPGPU&#39;s aren&#39;t
as cool anymore, everyone is selling effectively the same systems when
it comes to clusters. Not everyone has the budget to procure a specialist
machine like a NEC vector machine, a CRAY, Bluegene/Q etc&hellip;</p>

<p>The arms race to the top is just completely crazy, the top 50 or so
machines are so powerful compared to what a typical university or small
research lab might have access is too is completely skewed. At our site
we&#39;re probably about 0.5% of the top machine. In the past we were about
1-2% typically of the top machine, and we were about 5yrs behind the
curve. The top 500 list should really be renamed to the top 50 list and
the green 500 list or the HPCC list should be used instead as a measure
of the top machines in the world. Do people really think that LINPACK
is a good measure of how powerful a machine is going to be?</p>

<p>What was interesting at this year&#39;s conference was some of the papers
and panels were focused on project management and data management of
scientific datasets. I noticed that when people are starting to worry
about meta-data standards like librarians, people are starting to think
about archiving the data, they probably haven&#39;t thought about the access
component of preservation which will be amusing when they do realise
it. There is also a disconnect from some of the papers which focused on
silent data corruption at the storage and network layers. The archiving
and preservation space for HPC will need to deal with bit-flips, silent
data corruption, malicious users and all that funk that is related to it.</p>

<p>After having a few chats with some vendors during the week, /me eyes
them vendors. There seems to be a bit of a lack of understanding that
archiving and preservation of data isn&#39;t just about bulk, cheap and
reliable storage. There are apects to it which require data processing and
analytics of the data. It seems somewhat pointless to archive data and not
index it, process it and deliver it to who needs it. At somepoint the data
will be touched for checksumming, surrogate generation, delivery to the
end user. There also seems to be a lack of a guarantee of data-integrity
at the filesystem level. It appears that this responsiblity is left to
the application developer.</p>

<p>Would storage vendors (filesystems, devices the whole stack!) please
consider providing end to end data integrity? If the guys at the top are
trying to reach exascale computing in the next 5 years then the storage
component needs to catch up. Other sectors would also benefit from the
end to end data integrity built into storage systems.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[There is light on the otherside]]></title>
<link href="http://jcftang.github.com/2012/11/04/there-is-light-on-the-otherside/"/>
<updated>2012-11-04T19:52:00+00:00</updated>
<id>http://jcftang.github.com/2012/11/04/there-is-light-on-the-otherside</id>
<category term="dri" /><category term="linux" /><category term="scm" /><category term="team" />

      <content type="html"><![CDATA[<p>Having spent the best part of my Sunday afternoon playing with ansible
just to learn and see what all the fuss is about, I was pleasantly
surprised with it.</p>

<p>I had installed <a href="https://github.com/ansible/ansible">ansible</a> on my OSX
laptop and <a href="https://github.com/ansible/vagrant-ansible">vagrant-ansible</a>
for my vagrant test environment.</p>

<p>The plan was to try and re-create my current ruby on rails development
and test virtual machine with vagrant. A secondary goal was to get it
to work with both Ubuntu Precise (LTS) and Scientific Linux 6.</p>

<p>My attempt at doing the above can be found at
<a href="https://github.com/jcftang/tchpc-vagrant/tree/ansible">tchpc-vagrant</a>
in the ansible branch. You will need ansible installed on your host
machine. You don&#39;t need much installed in the target machine as ansible
is designed to login and execute commands as required, this is quite
refreshing. Compared to puppet and chef, if I were to roll this out
into production my overhead will be pretty low. This low overhead is
something that I really like as I don&#39;t need to setup an infrastructure
just to run puppet.</p>

<p>In short I was able to learn how ansible is supposed to work (I think)
and build up enough configuration to start up a vagrant vm with what I
need for to do rails development in a matter of hours.</p>

<p>One thing that did occur to me was the lack of windows support, given
that ansible is designed to use ssh to carry out its activities, finding
stock windows machines which run ssh is pretty slim. This is one area
which puppet (perhaps chef too) is better at. It&#39;s also one feature that
I would like as the vagrant vm&#39;s that we&#39;re using in work might be given
to windows users for testing and evaluation.</p>

<p>Going forward I think ansible will certainly be in my toolkit. There really is
a light on the otherside for mangement, deployment and orchestration.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Crowbar for deploying systems]]></title>
<link href="http://jcftang.github.com/2012/10/27/crowbar-for-deploying-systems/"/>
<updated>2012-10-27T20:07:00+01:00</updated>
<id>http://jcftang.github.com/2012/10/27/crowbar-for-deploying-systems</id>
<category term="linux" />

      <content type="html"><![CDATA[<p>I&#39;ve been eyeing <a href="https://github.com/dellcloudedge/crowbar">crowbar</a>
recently, it looks pretty useful and interesting for deploying servers
and applications. I haven&#39;t seen much if at all any documentation out
there which suggests that people in the digital preservation and archiving
fields are implementing systems at scale, I&#39;m under the impression that
most systems/sites are building systems up one piece at a time without
much automation.</p>

<p>It seems to use <a href="http://www.opscode.com/chef/">chef</a> in the backend for
all the automation. I&#39;ve been relearning <a href="http://puppetlabs.com/">puppet</a>
recently so that I can have reproducible environments with
<a href="http://vagrantup.com/">Vagrant</a>.</p>

<p>There might be an advantage to learn and port all the existing modules
that I have already created and configured to chef instead of puppet. If
I did move to a chef automation in my vagrant environments then a few
years from now when we go to full production we might be able to deploy
the whole system from bare metal relatively quickly and repeatably.</p>

<p>Automating the deployments will mean that we will have documentation
on the infrastructure itself. Either which way there is still a need
to automate the fedora-commons, SOLR, mysql and postgres deployments at
some point.</p>

<p>After all this thinking and pondering, I&#39;m still using puppet. There&#39;s
still the likes of ansible, cfengine, bcfg2 and juju. There is a never
ending supply of these tools.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.53 RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-53-released/"/>
<updated>2012-10-23T15:08:00+01:00</updated>
<id>http://jcftang.github.com/2012/10/23/ceph-v0-dot-53-released</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>There&#39;s a new release of Ceph, I hope that they release a stable soon so we can
do further evaluations of the Ceph storage
system. A few of my work colleagues are going to the <a href="http://www.inktank.com/news-events/event/ceph-workshops-amsterdam/">Ceph
workshop</a>
next week.</p>

<p>I&#39;m wondering if anyone has taken the CRUSH algorithm and used it in other
domains.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/10/23/ceph-v0-dot-53-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Hydracamp 2012 - Penn State &rarr;]]></title>
<link href="http://yourmediashelf.com/hydracamp/"/>
<updated>2012-10-13T07:34:00+01:00</updated>
<id>http://jcftang.github.com/2012/10/13/hydracamp-2012-penn-state</id>
<category term="dri" /><category term="preservation" /><category term="ruby" />

      <content type="html"><![CDATA[<p>What do you do when you need a crash course on RoR, Hydra and frameworks for
digital preservation and archiving? You go to Hydracamp!</p>

<p>The syllabus was</p>

<ul>
<li>Day 1 - Rails, CRUD, TDD and Git</li>
<li>Day 2 - Collaborative development with Stories, Tickets, TDD and Git</li>
<li>Day 3 - Hydra, Fedora, XML and RDF (ActiveFedora and OM)</li>
<li>Day 4 - SOLR and Blacklight</li>
<li>Day 5 - Hydra-head, Hydra Access Controls</li>
</ul>

<p>Most of the training sessions were hands on from day 1 which was
refreshing, as it was hands on I getting the most out of the training
session. It would have been better if I had known more ruby to move
along some of the exercises more effectively.</p>

<p>To give an overview of what we had done (between ~30 people), we created
a ruby on rails application titled &ldquo;Twitter for Zombies&rdquo;. With this small
application everybody was frantically committing, pulling, merging and
pushing code. It was highly informative and a good learning experience
to see how fast things could move.</p>

<p>The training session also included a crash course into what Fedora and
SOLR does and how Hydra interacts with these components. The third and
fourth days were the most interesting as it showed how someone might
convert from a typical RoR application into an application which uses
Fedora as the persistance layer. The last day was really just a wrap up
and Q&amp;A session.</p>

<p>You could take a look at the <a href="https://github.com/projecthydra">github</a>
account for Project Hydra and have a peek at the hydracamp repo.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/10/13/hydracamp-2012-penn-state/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Digital Preservation and Archiving is a HPC problem?]]></title>
<link href="http://jcftang.github.com/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/"/>
<updated>2012-10-07T13:42:00+01:00</updated>
<id>http://jcftang.github.com/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem</id>
<category term="hpc" /><category term="storage" />

      <content type="html"><![CDATA[<p>I shall be going to SC2012 next month, I plan on hitting a few of the
storage vendors for possible collaborations and flagging to them that
we&#39;re on the look out for storage systems. One of the first
observation that the reader will note is &ldquo;where is that link between
HPC and Digital Preservation and Archiving&rdquo;. It&#39;s probably not obvious
to most people, one of the big problems in the area of preservation
and archiving is the the amount of data involved and the varied types
of data. This is not taking into account of the issues with data
access patterns.</p>

<p>Given that a preservation and archiving project will want to provide a
trusted system, the system will want to read out every single byte
that was put in to verify that the data is correct at somepoint
(usually with some form of hashing).</p>

<p>Reading data out and checking that it&#39;s correct serially probably
isn&#39;t the smartest solution. Nor is copying the data into 2-3
locations (where each site is maintaining 2-3 copies for backups and
redundancy). The current and seemingly most popular solutions is to
dump the data to a few offsite locations (such as S3 or SWIFT)
compatible storage systems, then just hoping for the best that if
anyone of the sites is down or corrupted there site can be restored
from the other sites or from a backup. I need to delve deeper into the
storage and data-distribution strategies that some of the bigger
projects are taking. There has to be a smarter way of storing and
preserving data without having to make copies of things.</p>

<p>I&#39;ve often wondered how projects manage to copy/move data across
storage providers in a reasonable amount of time without needing to
wheel a few racks of disks around. It would also be interesting to see
the error rates of these systems and how often errors are
corrected. If they are corrected what is the computational cost of
doing this.</p>

<p>If you have a multi-terabyte archive the problem isn&#39;t too bad, the
more typical case these days might be in the order of the low hundreds
of terabytes. I could only imagine what lager scale sites must deal
with. I&#39;m still not a fan of moving a problem from a local site to a
remote site as it often shows that there is a lack of understanding to
the problem. Storage in the preservation and archiving domain will
probably turn into an IO and compute intensive operation at some
point, especially if you want to do something with the data.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[SLURM-Bank that big script for banking in SLURM &rarr;]]></title>
<link href="https://github.com/jcftang/slurm-bank"/>
<updated>2012-09-29T19:52:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm</id>
<category term="hpc" /><category term="linux" />

      <content type="html"><![CDATA[<p>A co-worker of mine (Paddy Doyle) had originally hacked at a perl script
for reporting balances from SLURM&#39;s accounting system a year or two ago
and he had figured out that it might be possible to do some minimalistic
&#39;configuration&#39; and scripting to get a system that&#39;s very basic but
functional.</p>

<p>It was just one of those things that funding agencies wanted to justify
how the system was being used, GOLD was clunky and obtrusive and
complicated for what we wanted. Most of all we liked SLURM but not GOLD
and Maui which was needed to get full accounting and banking (most of
the features weren&#39;t used).</p>

<p>Being good and lazy engineers we got excited with the prospect of having
the option of replacing SLURM, Maui and GOLD with just plain old SLURM
we set out to write down the workflows for what we wanted to do and what
the user and funding agencies actually wanted. With those ideas in mind
we set out to implement as much as we could and needed in just plain
old sh/bash scripting with a splash of perl. Replacing two components
with one meant that we would have less work to do in the long run ;)</p>

<p>After a whole year of running with these scripts and just putting it
online, I&#39;ve noticed that there may be a few sites out there that might
be using our scripts and workflows. It would be nice to find out how
many people are using our implementation of a banking system in SLURM
and if it&#39;s driven by sysadmins looking to account for usage or is it
funding agencies looking for justification of the usage of a system.</p>

<p>I was going to be at the SLURM User Group Meeting 2012 to give a
short talk on our experiences with the SLURM-Bank scripts and workflow,
but sadly I have to be in the US during this meeting and my colleague
&ldquo;Paddy Doyle&rdquo; will there instead of me.  I would have liked to go and chat
with the developers of SLURM to push for more advanced banking/accounting
facilities in SLURM itself. Visiting BSC again would have been fun.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.52 RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-52-released/"/>
<updated>2012-09-28T15:52:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/28/ceph-v0-dot-52-released</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>The latest development branch of Ceph is out with some rather nice
looking features, what&#39;s probably the most useful are the RPM builds
for those that run RHEL6 like systems.</p>

<p>Still no real sight of backported kernel modules :P Also some of the
guys in work here just deployed a ~200tb Ceph installation which I&#39;ve
access to a 10tb RBD for doing backups on.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/28/ceph-v0-dot-52-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[A poor man's NAS device with Ceph]]></title>
<link href="http://jcftang.github.com/2012/09/23/a-poor-mans-nas-device-with-ceph/"/>
<updated>2012-09-23T08:59:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/23/a-poor-mans-nas-device-with-ceph</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>Given that I have a number of old 64bit capable desktop machines and a
collection of hard drives at home, I could have run
<a href="https://tahoe-lafs.org/trac/tahoe-lafs">Tahoe-LAFS</a> like I do in work
for backup purposes. In fact Tahoe works quite well for the
technically capable user.</p>

<p>Recently I&#39;ve decided that I need a more central location at home to
store my photo collection (I love to take photos with my Canon DSLR
and Panasonic LX5). Traditionally I would have just fired up
<a href="http://git-annex.branchable.com/">git-annex</a> to track the data and
then setup a number of remotes to store the data, where one of them
might be Tahoe-LAFS and the rest might be portable hard drives, remote
machines etc&hellip;</p>

<p>I could have gone with any number of distributed storage solutions
such as <a href="http://www.gluster.org/">GlusterFS</a>,
<a href="http://www.irods.org">iRODS</a>,
<a href="http://xrootd.slac.stanford.edu/">xrootd</a>,
<a href="http://wiki.lustre.org/index.php/Main_Page">Lustre</a> or
<a href="http://www.xtreemfs.org/">xtreemfs</a>. I&#39;ve worked with some of these
systems in production and toyed with others. Since this is for a home
system I can pick what I want and change it at will.</p>

<p>I probably have 2-3tb&#39;s of data to archive and store, I also want easy
access to my data so NFS or CIFS exports are required. It wouldn&#39;t be
unfeasible to acquire a few 2 or 3 terabyte drives for my old desktop
machine which would effectively provide me with a 2 or 3 terabyte
replicated data store. Given the amount of toying around and learning
about Ceph in my spare time I would expect that Ceph would provide me
with a pretty good &ldquo;backend&rdquo; system for storing my files and the
option of &ldquo;migrating my data from one machine to another machine&rdquo; by
adding and removing OSD&#39;s. The handiest feature for me will be the
capability of expanding and shrinking the system as I need.</p>

<p>There probably aren&#39;t many people who would want to setup something
like this for a home system, but it is an alternative to the usual
RAID or LVM setup.</p>

<p>Here&#39;s my proposed setup which I&#39;m going to setup in the next few
spare weekends that I will have.</p>

<p><img class="" src="http://jcftang.github.com/downloads/images/ceph-home.png"></p>

<p>It would be great if Ceph offered some of of parity/erasure coding
instead of plain replication. I&#39;m greedy and I want to maximise my
disks that I have, I wonder how low I can go on hardware with the Ceph
software.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.48.2 ARGONAUT RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-48-2-argonaut-stable-update-released/"/>
<updated>2012-09-21T10:38:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>There&#39;s a new stable release of Ceph Argonaut, I seem to be having better
luck with playing with the development releases of Ceph.</p>

<p>Oh how I wish that there was a backport of the kernel ceph and rbd drivers
for RHEL6, I have a dodgy repo and some reverted commits that one of
the guys in work told me about. It seems to run but it isn&#39;t great,
it can be found at <a href="https://github.com/jcftang/ceph-client-standalone">https://github.com/jcftang/ceph-client-standalone</a>.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Alternative to Talend ETL?]]></title>
<link href="http://jcftang.github.com/2012/09/21/alternative-to-talend-etl/"/>
<updated>2012-09-21T10:31:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/21/alternative-to-talend-etl</id>


      <content type="html"><![CDATA[<p>I&#39;ve used Talend ETL a few times, however I came across this application
<a href="http://datacleaner.org/">http://datacleaner.org/</a>, I need to take a look at this somepoint to
see if its an alternative to Taled or not, or whether it works on a Mac
or not!</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Going from replicating across OSD's to replicating across hosts in a Ceph cluster]]></title>
<link href="http://jcftang.github.com/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/"/>
<updated>2012-09-06T21:44:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>Having learnt how to remove and add monitor&#39;s, meta-data and data servers (mon&#39;s, mds&#39;s
and osd&#39;s) for my small two node Ceph cluster. I want to say that it wasn&#39;t too hard to
do, the ceph website does have documentation for this.</p>

<p>As the default CRUSH map replicates across OSD&#39;s I wanted to try replicating data across
hosts just to see what would happen. In a real world scenario I would probably treat
individual hosts in a rack as a failure unit and if I had more than one rack of storage,
I would want to treat each rack as the minimum unit.</p>

<p>One of the coolest features of ceph is that it allows me to play with different mappings
and configurations of where my data gets allocated. There aren&#39;t many (if any) storage
systems that I know of which provides this type of capability.</p>

<p>So the steps that I went through to get to what I wanted&hellip;</p>

<p>First I had to dump the CRUSH map from my cluster of two nodes and three (very unbalanced OSD&#39;s so I can play with the weights).</p>
<div class="highlight"><pre><code class="text">ceph osd getcrushmap -o /tmp/mycrushmap
</code></pre></div>
<p>The CRUSH map that is created is a binary file it must be decoded to plain text before
you can edit it.</p>
<div class="highlight"><pre><code class="text">crushtool -d /tmp/mycrushmap &gt; /tmp/mycrushmap.txt
</code></pre></div>
<p>Here&#39;s the map that is decoded from the binary file</p>
<div class="highlight"><pre><code class="text"># begin crush map

# devices
device 0 osd.0
device 1 osd.1
device 2 osd.2

# types
type 0 osd
type 1 host
type 2 rack
type 3 row
type 4 room
type 5 datacenter
type 6 pool

# buckets
host x.y.z.194 {
        id -2           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item osd.1 weight 1.000
        item osd.0 weight 1.000
}
host x.y.z.138 {
        id -4           # do not change unnecessarily
        # weight 1.000
        alg straw
        hash 0  # rjenkins1
        item osd.2 weight 1.000
}
rack rack-1 {
        id -3           # do not change unnecessarily
        # weight 3.000
        alg straw
        hash 0  # rjenkins1
        item x.y.z.194 weight 2.000
        item x.y.z.138 weight 1.000
}
pool default {
        id -1           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item rack-1 weight 2.000
}

# rules
rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule metadata {
        ruleset 1
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule rbd {
        ruleset 2
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}

# end crush map
</code></pre></div>
<p>The relevant chunks of the config that I&#39;m interested in is the <strong>rule NAME {}</strong> blocks.
As I&#39;m interested in making my data, meta-data and probably my rbd rule replicate across hosts, I naturally made the rule look like this</p>
<div class="highlight"><pre><code class="text">rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step emit
}
</code></pre></div>
<p>The above change is apparently incorrect as the last step before the <em>step emit</em> needs
to be a device of some sort. I had found this out after posting the ceph-devel mailing
list. There were two proposed solutions (thanks to Greg from inktank), the first
proposed rule was</p>
<div class="highlight"><pre><code class="text">rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step choose firstn 1 osd
        step emit
}
</code></pre></div>
<p>Which selects <em>n</em> hosts then the first osd from each host, but it can&#39;t deal with an entire hosts failed OSD&#39;s. The second proposed rule was</p>
<div class="highlight"><pre><code class="text">rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step chooseleaf firstn 0 type host
        step emit
}
</code></pre></div>
<p>The above rule will select <em>n</em> hosts and an OSD from the host. It&#39;s pretty obvious that
the second rule is the one that I want. I would expect that if I had more machines in
racks and rows I could probably just replace host with rack, row or even data-center.</p>

<p>With the second proposed rule, I made the changes to <em>mycrushmap.txt</em>. Once the changes
are made, I had to compile the map into a binary format that the ceph cluster
understands, this can be done by</p>
<div class="highlight"><pre><code class="text">crushtool -c /tmp/mycrushmap.txt -o /tmp/mycrushmap.new
</code></pre></div>
<p>Once the map is compiled it must then be applied to the cluster</p>
<div class="highlight"><pre><code class="text">ceph osd setcrushmap -i /tmp/mycrushmap.new
</code></pre></div>
<p>The above is documented on the ceph website. Once I applied the new CRUSH map I ran a <em>ceph -w</em> to see that
the system had detected the changes and it then started to move data around on its own. I&#39;ll need to play
with pulling out the network cable or SATA cables to see how the system behaves from me causing catastrophic
failures in the test system.</p>

<p>I&#39;m pretty sure I took the long way around to making the changes, there must be a more dynamic way of
changing the system.</p>

<p>To recap and review the above operation, it&#39;s again no harder than my reference system that I know, which is
GPFS. GPFS doesn&#39;t allow me to do what ceph allows me to do. I would however like to see some more visible
documentation relating to the CRUSH configuration parameters and tuneables.</p>

<p>So far this has been a distraction from my main day job, but this will certainly help
with the project that I am working on in the long run.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Adding an OSD to a Ceph Cluster]]></title>
<link href="http://jcftang.github.com/2012/09/04/adding-an-osd-to-a-ceph-cluster/"/>
<updated>2012-09-04T18:42:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/04/adding-an-osd-to-a-ceph-cluster</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>Having created a small single node Ceph cluster with following the <a href="http://ceph.com/docs/master/start/quick-start/">5 minute quickstart</a> guide I was able to create a single node cluster with one OSD.</p>

<p>This probably wouldn&#39;t be the first post that someone has written about this topic.</p>

<p>I&#39;ve verified that it works in my test environment of Scientific Linux
6 by mounting the system with FUSE.</p>

<p>Here&#39;s my <em>fstab</em> to describe my disk layout</p>
<div class="highlight"><pre><code class="text"># /etc/fstab
# Created by anaconda on Fri Jul  6 14:27:56 2012
#
# Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/vg_ceres-lv_root /                     ext4    defaults,user_xattr        1 1
UUID=4eb5efad-dbcd-4a9f-8187-d8ffa913e147 /boot    ext4    defaults        1 2
/dev/mapper/vg_ceres-lv_home /data1                ext4 defaults,user_xattr        1 2
/dev/sdb /data                                     ext4 defaults,user_xattr        1 2
/dev/mapper/vg_ceres-lv_swap swap                  swap    defaults        0 0
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
</code></pre></div>
<p>Running a <em>df -h</em> gives this</p>
<div class="highlight"><pre><code class="text">$ df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_ceres-lv_root
               50G  5.5G   42G  12% /
tmpfs                 938M     0  938M   0% /dev/shm
/dev/sda1             485M   80M  380M  18% /boot
/dev/sdb              230G  1.2G  217G   1% /data
ceph-fuse             230G   13G  217G   6% /mnt
/dev/mapper/vg_ceres-lv_home
              176G  188M  167G   1% /data1
</code></pre></div>
<p>I&#39;m using an old desktop machine so I can plonk some &ldquo;files&rdquo; on it so I
can dogfood the test system in administering the bits and pieces of Ceph.</p>

<p>Here&#39;s my current Ceph configuration (before I add a new OSD)</p>
<div class="highlight"><pre><code class="text">[global]
    #auth supported = cephx
    #keyring = /etc/ceph/ceph.keyring
    filestore xattr use omap = true

[osd]
    osd journal size = 1000
    filestore xattr use omap = true

[mon.a]
    host = x.y.z.194
    mon addr = x.y.z.194:6789
    mon data = /data/mon.$id
[mds.a]
    host = x.y.z.194
    mon data = /data/mds.$id

[osd.0]
    host = x.y.z.194
    osd data = /data/osd.$id
    osd journal = /data/osd.$id.journal
</code></pre></div>
<p>I was a little caught out by the <em>osd journal</em> setting, I did not realise
that I needed to set this value if I set a journal size.</p>

<p>So to add a new OSD to a running system I followed the instructions at
<a href="http://ceph.com/docs/master/ops/manage/grow/osd/">http://ceph.com/docs/master/ops/manage/grow/osd/</a>. This involves
allocating a new OSD id, editting the ceph.conf file, formatting the
OSD then adjusting the CRUSH map to allocate data to the new OSD.</p>
<div class="highlight"><pre><code class="text">ceph osd create
1
</code></pre></div>
<p>I then added these lines to my ceph.conf file (as this is my test system,
I&#39;ve ignored all sensible naming conventions)</p>
<div class="highlight"><pre><code class="text">[osd.1]
    host = x.y.z.194
    osd data = /data$id/osd.$id
    osd journal = /data$id/osd.$id.journal
</code></pre></div>
<p>I then create the directory for osd.1</p>
<div class="highlight"><pre><code class="text">mkdir /data1/osd.1
</code></pre></div>
<p>Once the above is done, I need to initialise the osd data directory,
this can be done with the following command.</p>
<div class="highlight"><pre><code class="text">ceph-osd -i 1 --mkfs
</code></pre></div>
<p>As I am not using any authentication (for now) I do not bother with keys
and the such.</p>

<p>With the above done, one can verify that the OSD has been added to the
system by executing the following command</p>
<div class="highlight"><pre><code class="text"># ceph osd tree
dumped osdmap tree epoch 10
# id    weight  type name       up/down reweight
-1      1       pool default
-3      1               rack unknownrack
-2      1                       host x.y.z.194
0       1                               osd.0   up      1

1       0       osd.1   down    0
</code></pre></div>
<p>Once the osd is in the cluster, it must be added to the CRUSH map. Given the above, the command that I need to execute would be</p>
<div class="highlight"><pre><code class="text">ceph osd crush set 1 osd.1 1.0 pool=default rack=unknownrack host=x.y.z.194
</code></pre></div>
<p>Running the osd tree command again will show that I have added the OSD to my host</p>
<div class="highlight"><pre><code class="text"># ceph osd tree
dumped osdmap tree epoch 11
# id    weight  type name       up/down reweight
-1      2       pool default
-3      2               rack unknownrack
-2      2                       host x.y.z.194
0       1                               osd.0   up      1
1       1                               osd.1   down    0
</code></pre></div>
<p>However the state is down for <em>osd.1</em>, it must be brought up before it
is usable. It can be brought up by doing,</p>
<div class="highlight"><pre><code class="text"># service ceph -a start osd
# ceph osd tree
dumped osdmap tree epoch 13
# id    weight  type name       up/down reweight
-1      2       pool default
-3      2               rack unknownrack
-2      2                       host x.y.z.194
0       1                               osd.0   up      1
1       1                               osd.1   up      1
</code></pre></div>
<p>If I do a <em>df -h</em> I should see an increase in the space that is available.</p>
<div class="highlight"><pre><code class="text"># df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_ceres-lv_root
               50G  5.5G   42G  12% /
tmpfs                 938M     0  938M   0% /dev/shm
/dev/sda1             485M   80M  380M  18% /boot
/dev/sdb              230G  1.2G  217G   1% /data
ceph-fuse             405G   23G  382G   6% /mnt
/dev/mapper/vg_ceres-lv_home
                  176G  1.2G  166G   1% /data1
</code></pre></div>
<p>Given that I have in the past administered GPFS and Lustre filesystem
in production, this doesn&#39;t look too bad. I don&#39;t know the system that
well, but the configuration is pretty sensible and straight forward.</p>

<p>It&#39;s no harder than GPFS where one needs to create an NSD, then add the
NSD to a GPFS filesystem, nor is it more harder than just <em>mounting</em>
and OST in Lustre.</p>

<p>There does seem to be one or two additional things that a Ceph admin
would need to know before they can admin it optimally. However from the
initial playing around it looks like it needs more documentation, for
the seasoned parallel/distributed sysadmin this system is pretty neat
and tidy. However for the less experienced it looks like it might be a
bit hard to grasp some of the concepts before one can be an effective
admin of Ceph.</p>

<p>Now that I&#39;ve gone through the process of adding an OSD to my small test
cluster, I think the next thing to try is to play with the CRUSH map to
see if I can get Ceph replicate data between my OSD&#39;s even though
they are on the one machine. I guess the place to look at next is
<a href="http://ceph.com/wiki/Adjusting_replication_level">http://ceph.com/wiki/Adjusting_replication_level</a></p>

<p>Without getting into the finer details of all this, in GPFS you can only
have a replica size of 1 or 2 and you can only play with failure groups
of NSD&#39;s and nodes. GPFS does a lot to hide things from the admin, this
is probably a good thing. Lustre doesn&#39;t allow replicas at all (or
raid1). As powerful as Ceph is, I would imagine at some point someone
will ask &ldquo;can I just have a tool to set the replica count assuming I
have configured my machines and OSD lists accordingly&rdquo;</p>

<p>However the sysadmin in me just wants documentation as Ceph seems to
be almost ready for competing against GPFS and Lustre (as well as the
other parallel and distributed file systems).</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Scientific Linux 6 build environment for Ceph]]></title>
<link href="http://jcftang.github.com/2012/09/02/scientific-linux-6-build-environment-for-ceph/"/>
<updated>2012-09-02T10:50:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/02/scientific-linux-6-build-environment-for-ceph</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>After my last failed attempt at <a href="http://jcftang.github.com/2012/07/06/installing-ceph-on-sl6/">Installing Ceph on
SL6</a> or rather my attempt at
configuring Ceph for a test failed miserably.</p>

<p>It hasn&#39;t deterred me to test more. As a result I setup a number of
Vagrant Virtual machines and got together a few puppet scripts to
provision machines.</p>

<p>Here&#39;s a sample manifest for puppet to automate the deployment of a
machine to build Ceph. It requires that you SL6 environment to have at
least the epel repository enabled.</p>

<figure class='code'><figcaption>ceph.pp<a href='http://jcftang.github.com/downloads/code/puppet/manifests/nodes/ceph.pp'>view raw</a></figcaption><div class='highlight'><table><td class='line-numbers' aria-hidden='true'><pre><div data-line='1' class='line-number'></div><div data-line='2' class='line-number'></div><div data-line='3' class='line-number'></div><div data-line='4' class='line-number'></div><div data-line='5' class='line-number'></div><div data-line='6' class='line-number'></div><div data-line='7' class='line-number'></div><div data-line='8' class='line-number'></div><div data-line='9' class='line-number'></div><div data-line='10' class='line-number'></div><div data-line='11' class='line-number'></div><div data-line='12' class='line-number'></div><div data-line='13' class='line-number'></div><div data-line='14' class='line-number'></div><div data-line='15' class='line-number'></div><div data-line='16' class='line-number'></div><div data-line='17' class='line-number'></div><div data-line='18' class='line-number'></div><div data-line='19' class='line-number'></div><div data-line='20' class='line-number'></div><div data-line='21' class='line-number'></div><div data-line='22' class='line-number'></div><div data-line='23' class='line-number'></div><div data-line='24' class='line-number'></div><div data-line='25' class='line-number'></div><div data-line='26' class='line-number'></div><div data-line='27' class='line-number'></div><div data-line='28' class='line-number'></div><div data-line='29' class='line-number'></div><div data-line='30' class='line-number'></div><div data-line='31' class='line-number'></div><div data-line='32' class='line-number'></div><div data-line='33' class='line-number'></div><div data-line='34' class='line-number'></div><div data-line='35' class='line-number'></div><div data-line='36' class='line-number'></div><div data-line='37' class='line-number'></div><div data-line='38' class='line-number'></div><div data-line='39' class='line-number'></div><div data-line='40' class='line-number'></div><div data-line='41' class='line-number'></div><div data-line='42' class='line-number'></div><div data-line='43' class='line-number'></div><div data-line='44' class='line-number'></div><div data-line='45' class='line-number'></div><div data-line='46' class='line-number'></div><div data-line='47' class='line-number'></div><div data-line='48' class='line-number'></div><div data-line='49' class='line-number'></div><div data-line='50' class='line-number'></div><div data-line='51' class='line-number'></div><div data-line='52' class='line-number'></div><div data-line='53' class='line-number'></div><div data-line='54' class='line-number'></div><div data-line='55' class='line-number'></div><div data-line='56' class='line-number'></div><div data-line='57' class='line-number'></div><div data-line='58' class='line-number'></div><div data-line='59' class='line-number'></div><div data-line='60' class='line-number'></div><div data-line='61' class='line-number'></div><div data-line='62' class='line-number'></div><div data-line='63' class='line-number'></div><div data-line='64' class='line-number'></div><div data-line='65' class='line-number'></div><div data-line='66' class='line-number'></div><div data-line='67' class='line-number'></div><div data-line='68' class='line-number'></div><div data-line='69' class='line-number'></div><div data-line='70' class='line-number'></div><div data-line='71' class='line-number'></div><div data-line='72' class='line-number'></div><div data-line='73' class='line-number'></div><div data-line='74' class='line-number'></div><div data-line='75' class='line-number'></div><div data-line='76' class='line-number'></div><div data-line='77' class='line-number'></div><div data-line='78' class='line-number'></div><div data-line='79' class='line-number'></div><div data-line='80' class='line-number'></div><div data-line='81' class='line-number'></div><div data-line='82' class='line-number'></div><div data-line='83' class='line-number'></div><div data-line='84' class='line-number'></div><div data-line='85' class='line-number'></div><div data-line='86' class='line-number'></div><div data-line='87' class='line-number'></div></pre></td><td class='main  ruby'><pre><div class='line'><span class="c1"># -*- mode: ruby -*-</span>
</div><div class='line'><span class="c1"># vi: set ft=ruby :</span>
</div><div class='line'> </div><div class='line'><span class="c1">#</span>
</div><div class='line'><span class="c1"># template for tchpc site, there are dependancy issues with proxies</span>
</div><div class='line'><span class="c1">#</span>
</div><div class='line'><span class="n">node</span> <span class="sr">/ceph.*\.localhost/</span> <span class="n">inherits</span> <span class="n">default</span> <span class="p">{</span>
</div><div class='line'>    <span class="c1"># install needed packages</span>
</div><div class='line'>        <span class="c1"># generic devel tools and libraries</span>
</div><div class='line'>        <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nfs-utils&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nfs-utils&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;boost-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;boost-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;epel-release&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;epel-release&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;expat-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;expat-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fuse&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fuse&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fuse-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fuse-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gcc&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gcc&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gcc-c++&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gcc-c++&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;keyutils-libs-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;keyutils-libs-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libaio-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libaio-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libatomic_ops-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libatomic_ops-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libcurl-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libcurl-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libedit-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libedit-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libtool&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libtool&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libuuid-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libuuid-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libxml2-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libxml2-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nss&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nss&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nss-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nss-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;rpmdevtools&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;rpmdevtools&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>        <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;git&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;git&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># these two are form EPEL</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gperftools-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gperftools-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'>    <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fcgi-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fcgi-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># turn on avahi so we can do things like  &quot;ssh ceph00.local&quot; between the vm&#39;s</span>
</div><div class='line'>    <span class="kp">include</span> <span class="n">avahi</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># take the vagrant key for now and use it for passwordless ssh configs</span>
</div><div class='line'>        <span class="n">ssh_authorized_key</span> <span class="p">{</span> <span class="s2">&quot;root&quot;</span><span class="p">:</span>
</div><div class='line'>                <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="s2">&quot;present&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">type</span> <span class="o">=&gt;</span> <span class="s2">&quot;ssh-rsa&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">key</span> <span class="o">=&gt;</span> <span class="s2">&quot;AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ==&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="nb">name</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant insecure public key&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">user</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="p">}</span>
</div><div class='line'> </div><div class='line'>        <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/root/.ssh/id_rsa&quot;</span><span class="p">:</span>
</div><div class='line'>                <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_private_key&quot;</span> <span class="p">,</span>
</div><div class='line'>                <span class="nb">require</span> <span class="o">=&gt;</span> <span class="no">Ssh_authorized_key</span><span class="o">[</span><span class="s2">&quot;root&quot;</span><span class="o">]</span><span class="p">,</span>
</div><div class='line'>        <span class="p">}</span>
</div><div class='line'> </div><div class='line'>        <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/root/.ssh/config&quot;</span><span class="p">:</span>
</div><div class='line'>                <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_config&quot;</span><span class="p">,</span>
</div><div class='line'>                <span class="nb">require</span> <span class="o">=&gt;</span> <span class="no">Ssh_authorized_key</span><span class="o">[</span><span class="s2">&quot;root&quot;</span><span class="o">]</span><span class="p">,</span>
</div><div class='line'>        <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># the follow is done so the vagrant user can be used for testing and development without needing to su to the cephuser account</span>
</div><div class='line'>    <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/home/vagrant/.ssh/id_rsa&quot;</span><span class="p">:</span>
</div><div class='line'>        <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_private_key&quot;</span> <span class="p">,</span>
</div><div class='line'>    <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/home/vagrant/.ssh/config&quot;</span><span class="p">:</span>
</div><div class='line'>        <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</div><div class='line'>        <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_config&quot;</span><span class="p">,</span>
</div><div class='line'>    <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># define the hosts in /etc/hosts</span>
</div><div class='line'>    <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph00&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.130&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph00&#39;</span><span class="p">,</span> <span class="p">}</span>
</div><div class='line'>    <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph01&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.131&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph01&#39;</span><span class="p">,</span> <span class="p">}</span>
</div><div class='line'>    <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph02&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.132&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph02&#39;</span><span class="p">,</span> <span class="p">}</span>
</div><div class='line'> </div><div class='line'>   <span class="c1"># disable selinux</span>
</div><div class='line'>    <span class="k">class</span> <span class="p">{</span> <span class="s1">&#39;selinux&#39;</span><span class="p">:</span>
</div><div class='line'>        <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s1">&#39;disabled&#39;</span><span class="p">,</span>
</div><div class='line'>    <span class="p">}</span>
</div><div class='line'><span class="p">}</span>
</div></pre></td></tr></table></div></figure>

<p>Here&#39;s also a sample <em>Vagrantfile</em> to get one started</p>

<figure class='code'><figcaption>Vagrantfile </figcaption><div class='highlight'><table><td class='line-numbers' aria-hidden='true'><pre><div data-line='1' class='line-number'></div><div data-line='2' class='line-number'></div><div data-line='3' class='line-number'></div><div data-line='4' class='line-number'></div><div data-line='5' class='line-number'></div><div data-line='6' class='line-number'></div><div data-line='7' class='line-number'></div><div data-line='8' class='line-number'></div><div data-line='9' class='line-number'></div><div data-line='10' class='line-number'></div><div data-line='11' class='line-number'></div><div data-line='12' class='line-number'></div><div data-line='13' class='line-number'></div><div data-line='14' class='line-number'></div><div data-line='15' class='line-number'></div><div data-line='16' class='line-number'></div><div data-line='17' class='line-number'></div><div data-line='18' class='line-number'></div><div data-line='19' class='line-number'></div><div data-line='20' class='line-number'></div><div data-line='21' class='line-number'></div><div data-line='22' class='line-number'></div><div data-line='23' class='line-number'></div><div data-line='24' class='line-number'></div><div data-line='25' class='line-number'></div><div data-line='26' class='line-number'></div><div data-line='27' class='line-number'></div><div data-line='28' class='line-number'></div><div data-line='29' class='line-number'></div><div data-line='30' class='line-number'></div><div data-line='31' class='line-number'></div><div data-line='32' class='line-number'></div><div data-line='33' class='line-number'></div><div data-line='34' class='line-number'></div><div data-line='35' class='line-number'></div><div data-line='36' class='line-number'></div><div data-line='37' class='line-number'></div><div data-line='38' class='line-number'></div><div data-line='39' class='line-number'></div><div data-line='40' class='line-number'></div></pre></td><td class='main  ruby'><pre><div class='line'><span class="c1"># -*- mode: ruby -*-</span>
</div><div class='line'><span class="c1"># vi: set ft=ruby :</span>
</div><div class='line'> </div><div class='line'><span class="c1">#</span>
</div><div class='line'><span class="c1"># For vagrant configuration options please go to http://vagrantup.com/v1/docs/index.html</span>
</div><div class='line'><span class="c1">#</span>
</div><div class='line'> </div><div class='line'><span class="ss">Vagrant</span><span class="p">:</span><span class="ss">:Config</span><span class="o">.</span><span class="n">run</span> <span class="k">do</span> <span class="o">|</span><span class="n">global_config</span><span class="o">|</span>
</div><div class='line'>  <span class="c1"># All Vagrant configuration is done here. The most common configuration</span>
</div><div class='line'>  <span class="c1"># options are documented and commented below. For a complete reference,</span>
</div><div class='line'>  <span class="c1"># please see the online documentation at vagrantup.com.</span>
</div><div class='line'> </div><div class='line'>  <span class="c1"># Every Vagrant virtual environment requires a box to build off of.</span>
</div><div class='line'>  <span class="c1"># We default to using SL which is a RHEL clone</span>
</div><div class='line'>  <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">box</span> <span class="o">=</span> <span class="s2">&quot;sl63-x86_64&quot;</span>
</div><div class='line'>  <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">box_url</span> <span class="o">=</span> <span class="s2">&quot;http://thammuz.tchpc.tcd.ie/mirrors/boxes/scientificlinux-6.3-x86_64-netboot-devops.box&quot;</span>
</div><div class='line'>  <span class="n">cephServers</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="nb">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">|</span>
</div><div class='line'>    <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">define</span> <span class="nb">name</span> <span class="k">do</span> <span class="o">|</span><span class="n">ceph</span><span class="o">|</span>
</div><div class='line'>      <span class="c1"># uncomment the following line if you want the basebox to start in gui mode</span>
</div><div class='line'>      <span class="c1">#ceph.vm.boot_mode = :gui</span>
</div><div class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">network</span> <span class="ss">:hostonly</span><span class="p">,</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:network</span><span class="o">]</span>
</div><div class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">host_name</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:host_name</span><span class="o">]</span>
</div><div class='line'> </div><div class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">provision</span> <span class="ss">:puppet</span><span class="p">,</span> <span class="ss">:facter</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;ceph_node_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;ceph@</span><span class="si">#{</span><span class="n">opts</span><span class="o">[</span><span class="ss">:network</span><span class="o">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="p">}</span> <span class="k">do</span> <span class="o">|</span><span class="n">puppet</span><span class="o">|</span>
</div><div class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">manifest_file</span> <span class="o">=</span> <span class="s2">&quot;site.pp&quot;</span>
</div><div class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">manifests_path</span> <span class="o">=</span> <span class="s1">&#39;puppet/manifests&#39;</span>
</div><div class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">module_path</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;puppet/modules&#39;</span><span class="p">,</span> <span class="s1">&#39;puppet/services&#39;</span><span class="o">]</span>
</div><div class='line'>        <span class="c1">#puppet.options = &quot;--verbose --debug&quot;</span>
</div><div class='line'>      <span class="k">end</span>
</div><div class='line'> </div><div class='line'>    <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">customize</span> <span class="o">[</span>
</div><div class='line'>      <span class="s2">&quot;modifyvm&quot;</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span>
</div><div class='line'>      <span class="s2">&quot;--name&quot;</span><span class="p">,</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:host_name</span><span class="o">]</span><span class="p">,</span>
</div><div class='line'>      <span class="s2">&quot;--memory&quot;</span><span class="p">,</span> <span class="s2">&quot;1024&quot;</span>
</div><div class='line'>    <span class="o">]</span>
</div><div class='line'> </div><div class='line'>    <span class="k">end</span>
</div><div class='line'>  <span class="k">end</span>
</div><div class='line'> </div><div class='line'><span class="k">end</span>
</div></pre></td></tr></table></div></figure>

<p>With the Virtual Machines I was able to download the latest <a href="http://www.ceph.com/download/ceph-0.51.tar.bz2">Ceph
0.51</a> and do at least
the following</p>

<ul>
<li>unpack the tarball</li>
<li>do a <em>./configure</em> to generate the <em>ceph.spec</em> file</li>
<li>copy (or move) the ceph tarball into ~/rpmbuild/SOURCES</li>
<li>execute a <em>rpmbuild -ba ceph.spec</em> to build the source and binary rpm packages for installation</li>
</ul>

<p>After the RPM&#39;s were built and installed, I again followed the quick
guide at <a href="http://ceph.com/docs/master/start/quick-start/">http://ceph.com/docs/master/start/quick-start/</a> and was able
to setup a small 3 node cluster for playing around with.</p>

<p>So to note, I tried out the cephfs feature (via the fuse module) and
creating(destroying and resizing) RBD&#39;s. I haven&#39;t had a chance to
experiment with the kernel modules to actually do something useful with
the POSIX filesystem or RBD&#39;s that Ceph provides.</p>

<p>It would be worth nothing that the Ceph project are working on providing
prebuilt RPM&#39;s soon, there is already a <a href="http://ceph.com/gitbuilder-centos6-rpm-amd64/">gitbuilder instance for the rpm
build</a> or just go to their
<a href="http://ceph.com/gitbuilder.cgi">gitbuilder aggregator</a></p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[RCE 62: Ceph Petabyte Scale Storage &rarr;]]></title>
<link href="http://www.rce-cast.com/Podcast/rce-62-ceph-petabyte-scale-storage.html"/>
<updated>2012-09-01T19:42:00+01:00</updated>
<id>http://jcftang.github.com/2012/09/01/rce-62-ceph-petabyte-scale-storage</id>
<category term="ceph" /><category term="linux" /><category term="storage" />

      <content type="html"><![CDATA[<p>It&#39;s somewhat interesting to listen to, we&#39;ve been looking at
<a href="http://www.ceph.com/">ceph</a> for a few things in work.</p>

<p>Just jotting this down so I remember to share this with the guys in work.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/01/rce-62-ceph-petabyte-scale-storage/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Taking Vagrant and running with it]]></title>
<link href="http://jcftang.github.com/2012/08/28/taking-vagrant-and-running-with-it/"/>
<updated>2012-08-28T18:49:00+01:00</updated>
<id>http://jcftang.github.com/2012/08/28/taking-vagrant-and-running-with-it</id>
<category term="linux" /><category term="osx" /><category term="scm" /><category term="team" />

      <content type="html"><![CDATA[<p>Over past few weeks I&#39;ve been working on doing some integration and
testing work to try and deliver a prototype system. I&#39;ve taken the
<a href="http://vagrantup.com/">Vagrant</a> tool and puppet to try and deliver
systems for testing and development. Although the systems that I am
currently working with aren&#39;t fully automated, they are automated
enough for them to be easily started up by a developer who reads the
documentation (I hope).</p>

<p>I&#39;m hoping that by providing these disposable systems that the various
members in the team that I am working with will be more free to experiment
and less fearful of breaking the system. At best everyone will take the
idea on board and run with it as it does provide a common environment
for all members in the team and it encourages reproducibility of issues
and features.</p>

<p>One of the next steps of building up the development framework that I
now have is to introduce some of these concepts and the whole Vagrant
environment to the more front facing part of the team who need to deal
with stakeholders in the project. If our requirements and policy team have
constant up to date access to our development, testing and QA environment
along with the executable specifications (in the form of cucumber tests)
I hope to push forward communications between the stakeholders and the
team that I&#39;m working with.</p>

<p>For now I have one VM for the application itself and a number of
&ldquo;clusters&rdquo; of VM&#39;s which I had used for reviewing some technical
documentation, they are partially automated for others to
play with. Currently these scripts are internal to the project
only, but it&#39;s not hard to setup if you know how to configure
<a href="http://puppetlabs.com/">puppet</a>. Some of the scripts and ideas can
be found at <a href="https://github.com/jcftang/tchpc-vagrant">tchpc-vagrant</a>,
they&#39;re not great, but not bad either. I need more of the developers in
the team to use what I&#39;ve setup to evolve the system more for our use.</p>

<p>In parallel to using this for my day job, I&#39;ve
also setup a Vagrantfile for one of my pet projects
<a href="https://github.com/jcftang/cports">cports</a>. Using Vagrant for testing
builds and deployments of a packaging system has been great. I&#39;ve been
able to do clean rebuilds of various packages without fear of completely
polluting the enviroment, as its just a few commands away from being
redeployed and provisioned. I&#39;ll need to play more and then release it
to the HPC community (or those that care).</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[An excuse to learn Ruby and Ruby on Rails]]></title>
<link href="http://jcftang.github.com/2012/08/02/an-excuse-to-learn-ruby-and-ruby-on-rails/"/>
<updated>2012-08-02T18:15:00+01:00</updated>
<id>http://jcftang.github.com/2012/08/02/an-excuse-to-learn-ruby-and-ruby-on-rails</id>
<category term="dri" /><category term="ruby" /><category term="team" />

      <content type="html"><![CDATA[<p>I&#39;ve been a long time consumer of ruby applications but never quite
got around to learning the language and the frameworks that are
available to developers. Within the team that I have been working
with, we&#39;ve been evaluating <a href="http://projecthydra.org">hydra</a> as a
possible framework for our project.</p>

<p>I&#39;ve been spending the last few days reading
<a href="http://pragprog.com/book/achbd/the-rspec-book">The RSpec Book</a>, I&#39;ve
been able to pick up some of the basic syntax of the language from the
BDD book. As soon as I finish this book I will be moving on to a more
real world book relating to ruby with the goal of being able to
develop Ruby and Ruby on Rails applications.</p>

<p>Well, I didn&#39;t get as far as finishing the RSpec book and I&#39;ve started
creating a rubygem. I&#39;m attempting to expose the insides of
<a href="https://tahoe-lafs.org/trac/zfec/">zfec</a>, specifically the
functionality in <em>fec.c</em>. So far I&#39;ve been lazy and I am using swig to
automatically generate the C to ruby bindings with something like this</p>

<figure class='code'><figcaption>fec.i </figcaption><div class='highlight'><table><td class='line-numbers' aria-hidden='true'><pre><div data-line='1' class='line-number'></div><div data-line='2' class='line-number'></div><div data-line='3' class='line-number'></div><div data-line='4' class='line-number'></div><div data-line='5' class='line-number'></div><div data-line='6' class='line-number'></div><div data-line='7' class='line-number'></div><div data-line='8' class='line-number'></div><div data-line='9' class='line-number'></div><div data-line='10' class='line-number'></div></pre></td><td class='main  c'><pre><div class='line'><span class="o">%</span><span class="n">module</span> <span class="n">fec</span>
</div><div class='line'> </div><div class='line'><span class="o">%</span><span class="p">{</span>
</div><div class='line'><span class="cp">#include &quot;fec.h&quot;</span>
</div><div class='line'><span class="o">%</span><span class="p">}</span>
</div><div class='line'> </div><div class='line'><span class="n">fec_t</span><span class="o">*</span> <span class="n">fec_new</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">k</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">m</span><span class="p">);</span>
</div><div class='line'><span class="kt">void</span> <span class="nf">fec_free</span><span class="p">(</span><span class="n">fec_t</span><span class="o">*</span> <span class="n">p</span><span class="p">);</span>
</div><div class='line'><span class="kt">void</span> <span class="nf">fec_decode</span><span class="p">(</span><span class="k">const</span> <span class="n">fec_t</span><span class="o">*</span> <span class="n">code</span><span class="p">,</span> <span class="k">const</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">inpkts</span><span class="p">,</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">outpkts</span><span class="p">,</span> <span class="k">const</span> <span class="kt">unsigned</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">index</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">sz</span><span class="p">);</span>
</div><div class='line'><span class="kt">void</span> <span class="nf">fec_encode</span><span class="p">(</span><span class="k">const</span> <span class="n">fec_t</span><span class="o">*</span> <span class="n">code</span><span class="p">,</span> <span class="k">const</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">src</span><span class="p">,</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">fecs</span><span class="p">,</span> <span class="k">const</span> <span class="kt">unsigned</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">block_nums</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">num_block_nums</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">sz</span><span class="p">);</span>
</div></pre></td></tr></table></div></figure>

<p>Swig does it&#39;s thing,</p>

<figure class='code'><div class='highlight'><table><td class='line-numbers' aria-hidden='true'><pre><div data-line='1' class='line-number'></div></pre></td><td class='main  bash'><pre><div class='line'>swig -ruby fec.i
</div></pre></td></tr></table></div></figure>

<p>Amazingly after some fiddling I got ruby to load up the module. It
doesn&#39;t mean that it&#39;s going to do much though as I need to learn
about the typemaps in the ruby C interface do the correct mappings.</p>

<p>I&#39;m so far taking inspiration from the zfec python module to take a
stab at building a ruby equivalent package for the sake of learning
ruby and maybe even end up with something useful for the project that
I am working on in work.</p>

<p>After playing with extending ruby, I&#39;m thinking I may need to take a
step back and evaluate if this is the best way for me to learn ruby or
not. I should probably not mess too much extending the language with a
C library.</p>
]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[OSX Kernel panics and VirtualBox]]></title>
<link href="http://jcftang.github.com/2012/07/20/osx-kernel-panics-and-virtualbox/"/>
<updated>2012-07-20T20:49:00+01:00</updated>
<id>http://jcftang.github.com/2012/07/20/osx-kernel-panics-and-virtualbox</id>
<category term="osx" /><category term="team" />

      <content type="html"><![CDATA[<p>Having discovered <a href="http://vagrantup.com/">vagrant</a> and
<a href="https://github.com/jedi4ever/veewee">veewee</a> recently at OR2012 I&#39;ve
been building a few <em>boxes</em> for our site for testing purposes. I&#39;ve
had to relearn puppet to provision machines, but it&#39;s paying off. I&#39;ve
been able to deploy 3-4 virtual machines with relative ease.</p>

<p>The only disappointment is the seemingly frequent and semi-random
kernel panics and crashes that I get on OSX (which is probably caused
by VirtualBox when I do lots of IO). It&#39;s making me rethink if I
really want to stick with OSX as my primary desktop OS in work. I may
have to revert back to using Linux at somepoint.</p>

<p>At least in Linux I know how to get a kdump out and debug the issue
but with OSX I&#39;m not sure where I should begin to figure out what&#39;s
broken.</p>
]]></content>
    </entry>
  
</feed>
