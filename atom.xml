<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Jimmy Tang]]></title>
  <link href="http://jcftang.github.com/atom.xml" rel="self"/>
  <link href="http://jcftang.github.com/"/>
  <updated>2012-10-13T09:50:37-04:00</updated>
  <id>http://jcftang.github.com/</id>
  <author>
    <name><![CDATA[Jimmy Tang]]></name>
    <email><![CDATA[jcftang@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      




<title type="html"><![CDATA[Hydracamp 2012 - Penn State &rarr;]]></title>
<link href="http://yourmediashelf.com/hydracamp/"/>
<updated>2012-10-13T07:34:00-04:00</updated>
<id>http://jcftang.github.com/2012/10/13/hydracamp-2012-penn-state</id>

      <content type="html"><![CDATA[<p>What do you do when you need a crash course on RoR, Hydra and frameworks for
digital preservation and archiving? You go to Hydracamp!</p>

<p>The syllabus was</p>

<ul>
<li>Day 1 - Rails, CRUD, TDD and Git</li>
<li>Day 2 - Collaborative development with Stories, Tickets, TDD and Git</li>
<li>Day 3 - Hydra, Fedora, XML and RDF (ActiveFedora and OM)</li>
<li>Day 4 - SOLR and Blacklight</li>
<li>Day 5 - Hydra-head, Hydra Access Controls</li>
</ul>


<p>Most of the training sessions were hands on from day 1 which was
refreshing, as it was hands on I getting the most out of the training
session. It would have been better if I had known more ruby to move
along some of the exercises more effectively.</p>

<p>To give an overview of what we had done (between ~30 people), we created
a ruby on rails application titled &#8220;Twitter for Zombies&#8221;. With this small
application everybody was frantically committing, pulling, merging and
pushing code. It was highly informative and a good learning experience
to see how fast things could move.</p>

<p>The training session also included a crash course into what Fedora and
SOLR does and how Hydra interacts with these components. The third and
fourth days were the most interesting as it showed how someone might
convert from a typical RoR application into an application which uses
Fedora as the persistance layer. The last day was really just a wrap up
and Q&amp;A session.</p>

<p>You could take a look at the <a href="https://github.com/projecthydra">github</a>
account for Project Hydra and have a peek at the hydracamp repo.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/10/13/hydracamp-2012-penn-state/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Digital Preservation and Archiving is a HPC problem?]]></title>
<link href="http://jcftang.github.com/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/"/>
<updated>2012-10-07T13:42:00-04:00</updated>
<id>http://jcftang.github.com/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem</id>

      <content type="html"><![CDATA[<p>I shall be going to SC2012 next month, I plan on hitting a few of the
storage vendors for possible collaborations and flagging to them that
we&#8217;re on the look out for storage systems. One of the first
observation that the reader will note is &#8220;where is that link between
HPC and Digital Preservation and Archiving&#8221;. It&#8217;s probably not obvious
to most people, one of the big problems in the area of preservation
and archiving is the the amount of data involved and the varied types
of data. This is not taking into account of the issues with data
access patterns.</p>

<p>Given that a preservation and archiving project will want to provide a
trusted system, the system will want to read out every single byte
that was put in to verify that the data is correct at somepoint
(usually with some form of hashing).</p>

<p>Reading data out and checking that it&#8217;s correct serially probably
isn&#8217;t the smartest solution. Nor is copying the data into 2-3
locations (where each site is maintaining 2-3 copies for backups and
redundancy). The current and seemingly most popular solutions is to
dump the data to a few offsite locations (such as S3 or SWIFT)
compatible storage systems, then just hoping for the best that if
anyone of the sites is down or corrupted there site can be restored
from the other sites or from a backup. I need to delve deeper into the
storage and data-distribution strategies that some of the bigger
projects are taking. There has to be a smarter way of storing and
preserving data without having to make copies of things.</p>

<p>I&#8217;ve often wondered how projects manage to copy/move data across
storage providers in a reasonable amount of time without needing to
wheel a few racks of disks around. It would also be interesting to see
the error rates of these systems and how often errors are
corrected. If they are corrected what is the computational cost of
doing this.</p>

<p>If you have a multi-terabyte archive the problem isn&#8217;t too bad, the
more typical case these days might be in the order of the low hundreds
of terabytes. I could only imagine what lager scale sites must deal
with. I&#8217;m still not a fan of moving a problem from a local site to a
remote site as it often shows that there is a lack of understanding to
the problem. Storage in the preservation and archiving domain will
probably turn into an IO and compute intensive operation at some
point, especially if you want to do something with the data.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/10/07/digital-preservation-and-archiving-is-a-hpc-problem/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[SLURM-Bank that big script for banking in SLURM &rarr;]]></title>
<link href="https://github.com/jcftang/slurm-bank"/>
<updated>2012-09-29T19:52:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm</id>

      <content type="html"><![CDATA[<p>A co-worker of mine (Paddy Doyle) had originally hacked at a perl script
for reporting balances from SLURM&#8217;s accounting system a year or two ago
and he had figured out that it might be possible to do some minimalistic
&#8216;configuration&#8217; and scripting to get a system that&#8217;s very basic but
functional.</p>

<p>It was just one of those things that funding agencies wanted to justify
how the system was being used, GOLD was clunky and obtrusive and
complicated for what we wanted. Most of all we liked SLURM but not GOLD
and Maui which was needed to get full accounting and banking (most of
the features weren&#8217;t used).</p>

<p>Being good and lazy engineers we got excited with the prospect of having
the option of replacing SLURM, Maui and GOLD with just plain old SLURM
we set out to write down the workflows for what we wanted to do and what
the user and funding agencies actually wanted. With those ideas in mind
we set out to implement as much as we could and needed in just plain
old sh/bash scripting with a splash of perl. Replacing two components
with one meant that we would have less work to do in the long run ;)</p>

<p>After a whole year of running with these scripts and just putting it
online, I&#8217;ve noticed that there may be a few sites out there that might
be using our scripts and workflows. It would be nice to find out how
many people are using our implementation of a banking system in SLURM
and if it&#8217;s driven by sysadmins looking to account for usage or is it
funding agencies looking for justification of the usage of a system.</p>

<p>I was going to be at the SLURM User Group Meeting 2012 to give a
short talk on our experiences with the SLURM-Bank scripts and workflow,
but sadly I have to be in the US during this meeting and my colleague
&#8220;Paddy Doyle&#8221; will there instead of me.  I would have liked to go and chat
with the developers of SLURM to push for more advanced banking/accounting
facilities in SLURM itself. Visiting BSC again would have been fun.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/29/slurm-bank-that-big-script-for-banking-in-slurm/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.52 RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-52-released/"/>
<updated>2012-09-28T15:52:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/28/ceph-v0-dot-52-released</id>

      <content type="html"><![CDATA[<p>The latest development branch of Ceph is out with some rather nice
looking features, what&#8217;s probably the most useful are the RPM builds
for those that run RHEL6 like systems.</p>

<p>Still no real sight of backported kernel modules :P Also some of the
guys in work here just deployed a ~200tb Ceph installation which I&#8217;ve
access to a 10tb RBD for doing backups on.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/28/ceph-v0-dot-52-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[A poor man's NAS device with Ceph]]></title>
<link href="http://jcftang.github.com/2012/09/23/a-poor-mans-nas-device-with-ceph/"/>
<updated>2012-09-23T08:59:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/23/a-poor-mans-nas-device-with-ceph</id>

      <content type="html"><![CDATA[<p>Given that I have a number of old 64bit capable desktop machines and a
collection of hard drives at home, I could have run
<a href="https://tahoe-lafs.org/trac/tahoe-lafs">Tahoe-LAFS</a> like I do in work
for backup purposes. In fact Tahoe works quite well for the
technically capable user.</p>

<p>Recently I&#8217;ve decided that I need a more central location at home to
store my photo collection (I love to take photos with my Canon DSLR
and Panasonic LX5). Traditionally I would have just fired up
<a href="http://git-annex.branchable.com/">git-annex</a> to track the data and
then setup a number of remotes to store the data, where one of them
might be Tahoe-LAFS and the rest might be portable hard drives, remote
machines etc&#8230;</p>

<p>I could have gone with any number of distributed storage solutions
such as <a href="http://www.gluster.org/">GlusterFS</a>,
<a href="http://www.irods.org">iRODS</a>,
<a href="http://xrootd.slac.stanford.edu/">xrootd</a>,
<a href="http://wiki.lustre.org/index.php/Main_Page">Lustre</a> or
<a href="http://www.xtreemfs.org/">xtreemfs</a>. I&#8217;ve worked with some of these
systems in production and toyed with others. Since this is for a home
system I can pick what I want and change it at will.</p>

<p>I probably have 2-3tb&#8217;s of data to archive and store, I also want easy
access to my data so NFS or CIFS exports are required. It wouldn&#8217;t be
unfeasible to acquire a few 2 or 3 terabyte drives for my old desktop
machine which would effectively provide me with a 2 or 3 terabyte
replicated data store. Given the amount of toying around and learning
about Ceph in my spare time I would expect that Ceph would provide me
with a pretty good &#8220;backend&#8221; system for storing my files and the
option of &#8220;migrating my data from one machine to another machine&#8221; by
adding and removing OSD&#8217;s. The handiest feature for me will be the
capability of expanding and shrinking the system as I need.</p>

<p>There probably aren&#8217;t many people who would want to setup something
like this for a home system, but it is an alternative to the usual
RAID or LVM setup.</p>

<p>Here&#8217;s my proposed setup which I&#8217;m going to setup in the next few
spare weekends that I will have.</p>

<p><img class="" src="http://jcftang.github.com/downloads/images/ceph-home.png"></p>

<p>It would be great if Ceph offered some of of parity/erasure coding
instead of plain replication. I&#8217;m greedy and I want to maximise my
disks that I have, I wonder how low I can go on hardware with the Ceph
software.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/23/a-poor-mans-nas-device-with-ceph/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.48.2 ARGONAUT RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-48-2-argonaut-stable-update-released/"/>
<updated>2012-09-21T10:38:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released</id>

      <content type="html"><![CDATA[<p>There&#8217;s a new stable release of Ceph Argonaut, I seem to be having better
luck with playing with the development releases of Ceph.</p>

<p>Oh how I wish that there was a backport of the kernel ceph and rbd drivers
for RHEL6, I have a dodgy repo and some reverted commits that one of
the guys in work told me about. It seems to run but it isn&#8217;t great,
it can be found at <a href="https://github.com/jcftang/ceph-client-standalone">https://github.com/jcftang/ceph-client-standalone</a>.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/21/ceph-v0-dot-48-dot-2-argonaut-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Going from replicating across OSD's to replicating across hosts in a Ceph cluster]]></title>
<link href="http://jcftang.github.com/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/"/>
<updated>2012-09-06T21:44:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster</id>

      <content type="html"><![CDATA[<p>Having learnt how to remove and add monitor&#8217;s, meta-data and data servers (mon&#8217;s, mds&#8217;s
and osd&#8217;s) for my small two node Ceph cluster. I want to say that it wasn&#8217;t too hard to
do, the ceph website does have documentation for this.</p>

<p>As the default CRUSH map replicates across OSD&#8217;s I wanted to try replicating data across
hosts just to see what would happen. In a real world scenario I would probably treat
individual hosts in a rack as a failure unit and if I had more than one rack of storage,
I would want to treat each rack as the minimum unit.</p>

<p>One of the coolest features of ceph is that it allows me to play with different mappings
and configurations of where my data gets allocated. There aren&#8217;t many (if any) storage
systems that I know of which provides this type of capability.</p>

<p>So the steps that I went through to get to what I wanted&#8230;</p>

<p>First I had to dump the CRUSH map from my cluster of two nodes and three (very unbalanced OSD&#8217;s so I can play with the weights).</p>

<pre><code>ceph osd getcrushmap -o /tmp/mycrushmap
</code></pre>

<p>The CRUSH map that is created is a binary file it must be decoded to plain text before
you can edit it.</p>

<pre><code>crushtool -d /tmp/mycrushmap &gt; /tmp/mycrushmap.txt
</code></pre>

<p>Here&#8217;s the map that is decoded from the binary file</p>

<pre><code># begin crush map

# devices
device 0 osd.0
device 1 osd.1
device 2 osd.2

# types
type 0 osd
type 1 host
type 2 rack
type 3 row
type 4 room
type 5 datacenter
type 6 pool

# buckets
host x.y.z.194 {
        id -2           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item osd.1 weight 1.000
        item osd.0 weight 1.000
}
host x.y.z.138 {
        id -4           # do not change unnecessarily
        # weight 1.000
        alg straw
        hash 0  # rjenkins1
        item osd.2 weight 1.000
}
rack rack-1 {
        id -3           # do not change unnecessarily
        # weight 3.000
        alg straw
        hash 0  # rjenkins1
        item x.y.z.194 weight 2.000
        item x.y.z.138 weight 1.000
}
pool default {
        id -1           # do not change unnecessarily
        # weight 2.000
        alg straw
        hash 0  # rjenkins1
        item rack-1 weight 2.000
}

# rules
rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule metadata {
        ruleset 1
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}
rule rbd {
        ruleset 2
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type osd
        step emit
}

# end crush map
</code></pre>

<p>The relevant chunks of the config that I&#8217;m interested in is the <strong>rule NAME {}</strong> blocks.
As I&#8217;m interested in making my data, meta-data and probably my rbd rule replicate across hosts, I naturally made the rule look like this</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step emit
}
</code></pre>

<p>The above change is apparently incorrect as the last step before the <em>step emit</em> needs
to be a device of some sort. I had found this out after posting the ceph-devel mailing
list. There were two proposed solutions (thanks to Greg from inktank), the first
proposed rule was</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step choose firstn 0 type host
        step choose firstn 1 osd
        step emit
}
</code></pre>

<p>Which selects <em>n</em> hosts then the first osd from each host, but it can&#8217;t deal with an entire hosts failed OSD&#8217;s. The second proposed rule was</p>

<pre><code>rule data {
        ruleset 0
        type replicated
        min_size 1
        max_size 10
        step take default
        step chooseleaf firstn 0 type host
        step emit
}
</code></pre>

<p>The above rule will select <em>n</em> hosts and an OSD from the host. It&#8217;s pretty obvious that
the second rule is the one that I want. I would expect that if I had more machines in
racks and rows I could probably just replace host with rack, row or even data-center.</p>

<p>With the second proposed rule, I made the changes to <em>mycrushmap.txt</em>. Once the changes
are made, I had to compile the map into a binary format that the ceph cluster
understands, this can be done by</p>

<pre><code>crushtool -c /tmp/mycrushmap.txt -o /tmp/mycrushmap.new
</code></pre>

<p>Once the map is compiled it must then be applied to the cluster</p>

<pre><code>ceph osd setcrushmap -i /tmp/mycrushmap.new
</code></pre>

<p>The above is documented on the ceph website. Once I applied the new CRUSH map I ran a <em>ceph -w</em> to see that
the system had detected the changes and it then started to move data around on its own. I&#8217;ll need to play
with pulling out the network cable or SATA cables to see how the system behaves from me causing catastrophic
failures in the test system.</p>

<p>I&#8217;m pretty sure I took the long way around to making the changes, there must be a more dynamic way of
changing the system.</p>

<p>To recap and review the above operation, it&#8217;s again no harder than my reference system that I know, which is
GPFS. GPFS doesn&#8217;t allow me to do what ceph allows me to do. I would however like to see some more visible
documentation relating to the CRUSH configuration parameters and tuneables.</p>

<p>So far this has been a distraction from my main day job, but this will certainly help
with the project that I am working on in the long run.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/06/going-from-replicating-across-osds-to-replicating-across-hosts-in-a-ceph-cluster/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Adding an OSD to a Ceph Cluster]]></title>
<link href="http://jcftang.github.com/2012/09/04/adding-an-osd-to-a-ceph-cluster/"/>
<updated>2012-09-04T18:42:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/04/adding-an-osd-to-a-ceph-cluster</id>

      <content type="html"><![CDATA[<p>Having created a small single node Ceph cluster with following the <a href="http://ceph.com/docs/master/start/quick-start/">5 minute quickstart</a> guide I was able to create a single node cluster with one OSD.</p>

<p>This probably wouldn&#8217;t be the first post that someone has written about this topic.</p>

<p>I&#8217;ve verified that it works in my test environment of Scientific Linux
6 by mounting the system with FUSE.</p>

<p>Here&#8217;s my <em>fstab</em> to describe my disk layout</p>

<pre><code># /etc/fstab
# Created by anaconda on Fri Jul  6 14:27:56 2012
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/vg_ceres-lv_root /                     ext4    defaults,user_xattr        1 1
UUID=4eb5efad-dbcd-4a9f-8187-d8ffa913e147 /boot    ext4    defaults        1 2
/dev/mapper/vg_ceres-lv_home /data1                ext4 defaults,user_xattr        1 2
/dev/sdb /data                                     ext4 defaults,user_xattr        1 2
/dev/mapper/vg_ceres-lv_swap swap                  swap    defaults        0 0
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
</code></pre>

<p>Running a <em>df -h</em> gives this</p>

<pre><code>$ df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_ceres-lv_root
               50G  5.5G   42G  12% /
tmpfs                 938M     0  938M   0% /dev/shm
/dev/sda1             485M   80M  380M  18% /boot
/dev/sdb              230G  1.2G  217G   1% /data
ceph-fuse             230G   13G  217G   6% /mnt
/dev/mapper/vg_ceres-lv_home
              176G  188M  167G   1% /data1
</code></pre>

<p>I&#8217;m using an old desktop machine so I can plonk some &#8220;files&#8221; on it so I
can dogfood the test system in administering the bits and pieces of Ceph.</p>

<p>Here&#8217;s my current Ceph configuration (before I add a new OSD)</p>

<pre><code>[global]
    #auth supported = cephx
    #keyring = /etc/ceph/ceph.keyring
    filestore xattr use omap = true

[osd]
    osd journal size = 1000
    filestore xattr use omap = true

[mon.a]
    host = x.y.z.194
    mon addr = x.y.z.194:6789
    mon data = /data/mon.$id
[mds.a]
    host = x.y.z.194
    mon data = /data/mds.$id

[osd.0]
    host = x.y.z.194
    osd data = /data/osd.$id
    osd journal = /data/osd.$id.journal
</code></pre>

<p>I was a little caught out by the <em>osd journal</em> setting, I did not realise
that I needed to set this value if I set a journal size.</p>

<p>So to add a new OSD to a running system I followed the instructions at
<a href="http://ceph.com/docs/master/ops/manage/grow/osd/">http://ceph.com/docs/master/ops/manage/grow/osd/</a>. This involves
allocating a new OSD id, editting the ceph.conf file, formatting the
OSD then adjusting the CRUSH map to allocate data to the new OSD.</p>

<pre><code>ceph osd create
1
</code></pre>

<p>I then added these lines to my ceph.conf file (as this is my test system,
I&#8217;ve ignored all sensible naming conventions)</p>

<pre><code>[osd.1]
    host = x.y.z.194
    osd data = /data$id/osd.$id
    osd journal = /data$id/osd.$id.journal
</code></pre>

<p>I then create the directory for osd.1</p>

<pre><code>mkdir /data1/osd.1
</code></pre>

<p>Once the above is done, I need to initialise the osd data directory,
this can be done with the following command.</p>

<pre><code>ceph-osd -i 1 --mkfs
</code></pre>

<p>As I am not using any authentication (for now) I do not bother with keys
and the such.</p>

<p>With the above done, one can verify that the OSD has been added to the
system by executing the following command</p>

<pre><code># ceph osd tree
dumped osdmap tree epoch 10
# id    weight  type name       up/down reweight
-1      1       pool default
-3      1               rack unknownrack
-2      1                       host x.y.z.194
0       1                               osd.0   up      1

1       0       osd.1   down    0
</code></pre>

<p>Once the osd is in the cluster, it must be added to the CRUSH map. Given the above, the command that I need to execute would be</p>

<pre><code>ceph osd crush set 1 osd.1 1.0 pool=default rack=unknownrack host=x.y.z.194
</code></pre>

<p>Running the osd tree command again will show that I have added the OSD to my host</p>

<pre><code># ceph osd tree
dumped osdmap tree epoch 11
# id    weight  type name       up/down reweight
-1      2       pool default
-3      2               rack unknownrack
-2      2                       host x.y.z.194
0       1                               osd.0   up      1
1       1                               osd.1   down    0
</code></pre>

<p>However the state is down for <em>osd.1</em>, it must be brought up before it
is usable. It can be brought up by doing,</p>

<pre><code># service ceph -a start osd
# ceph osd tree
dumped osdmap tree epoch 13
# id    weight  type name       up/down reweight
-1      2       pool default
-3      2               rack unknownrack
-2      2                       host x.y.z.194
0       1                               osd.0   up      1
1       1                               osd.1   up      1
</code></pre>

<p>If I do a <em>df -h</em> I should see an increase in the space that is available.</p>

<pre><code># df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/vg_ceres-lv_root
               50G  5.5G   42G  12% /
tmpfs                 938M     0  938M   0% /dev/shm
/dev/sda1             485M   80M  380M  18% /boot
/dev/sdb              230G  1.2G  217G   1% /data
ceph-fuse             405G   23G  382G   6% /mnt
/dev/mapper/vg_ceres-lv_home
                  176G  1.2G  166G   1% /data1
</code></pre>

<p>Given that I have in the past administered GPFS and Lustre filesystem
in production, this doesn&#8217;t look too bad. I don&#8217;t know the system that
well, but the configuration is pretty sensible and straight forward.</p>

<p>It&#8217;s no harder than GPFS where one needs to create an NSD, then add the
NSD to a GPFS filesystem, nor is it more harder than just <em>mounting</em>
and OST in Lustre.</p>

<p>There does seem to be one or two additional things that a Ceph admin
would need to know before they can admin it optimally. However from the
initial playing around it looks like it needs more documentation, for
the seasoned parallel/distributed sysadmin this system is pretty neat
and tidy. However for the less experienced it looks like it might be a
bit hard to grasp some of the concepts before one can be an effective
admin of Ceph.</p>

<p>Now that I&#8217;ve gone through the process of adding an OSD to my small test
cluster, I think the next thing to try is to play with the CRUSH map to
see if I can get Ceph replicate data between my OSD&#8217;s even though
they are on the one machine. I guess the place to look at next is
<a href="http://ceph.com/wiki/Adjusting_replication_level">http://ceph.com/wiki/Adjusting_replication_level</a></p>

<p>Without getting into the finer details of all this, in GPFS you can only
have a replica size of 1 or 2 and you can only play with failure groups
of NSD&#8217;s and nodes. GPFS does a lot to hide things from the admin, this
is probably a good thing. Lustre doesn&#8217;t allow replicas at all (or
raid1). As powerful as Ceph is, I would imagine at some point someone
will ask &#8220;can I just have a tool to set the replica count assuming I
have configured my machines and OSD lists accordingly&#8221;</p>

<p>However the sysadmin in me just wants documentation as Ceph seems to
be almost ready for competing against GPFS and Lustre (as well as the
other parallel and distributed file systems).</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/04/adding-an-osd-to-a-ceph-cluster/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Scientific Linux 6 build environment for Ceph]]></title>
<link href="http://jcftang.github.com/2012/09/02/scientific-linux-6-build-environment-for-ceph/"/>
<updated>2012-09-02T10:50:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/02/scientific-linux-6-build-environment-for-ceph</id>

      <content type="html"><![CDATA[<p>After my last failed attempt at <a href="http://jcftang.github.com/2012/07/06/installing-ceph-on-sl6/">Installing Ceph on
SL6</a> or rather my attempt at
configuring Ceph for a test failed miserably.</p>

<p>It hasn&#8217;t deterred me to test more. As a result I setup a number of
Vagrant Virtual machines and got together a few puppet scripts to
provision machines.</p>

<p>Here&#8217;s a sample manifest for puppet to automate the deployment of a
machine to build Ceph. It requires that you SL6 environment to have at
least the epel repository enabled.</p>

<figure class='code'><figcaption><span>ceph.pp</span><a href='http://jcftang.github.com/downloads/code/puppet/manifests/nodes/ceph.pp' title='Download code'> download</a></figcaption><div class='highlight'><table><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># -*- mode: ruby -*-</span>
</span><span class='line'><span class="c1"># vi: set ft=ruby :</span>
</span><span class='line'>
</span><span class='line'><span class="c1">#</span>
</span><span class='line'><span class="c1"># template for tchpc site, there are dependancy issues with proxies</span>
</span><span class='line'><span class="c1">#</span>
</span><span class='line'><span class="n">node</span> <span class="sr">/ceph.*\.localhost/</span> <span class="n">inherits</span> <span class="n">default</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1"># install needed packages</span>
</span><span class='line'>        <span class="c1"># generic devel tools and libraries</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nfs-utils&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nfs-utils&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;boost-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;boost-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;epel-release&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;epel-release&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;expat-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;expat-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fuse&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fuse&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fuse-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fuse-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gcc&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gcc&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gcc-c++&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gcc-c++&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;keyutils-libs-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;keyutils-libs-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libaio-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libaio-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libatomic_ops-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libatomic_ops-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libcurl-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libcurl-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libedit-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libedit-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libtool&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libtool&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libuuid-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libuuid-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;libxml2-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;libxml2-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nss&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nss&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;nss-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;nss-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;rpmdevtools&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;rpmdevtools&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;git&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;git&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># these two are form EPEL</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;gperftools-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;gperftools-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">!</span> <span class="n">defined</span><span class="p">(</span><span class="no">Package</span><span class="o">[</span><span class="s1">&#39;fcgi-devel&#39;</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="n">package</span> <span class="p">{</span> <span class="s1">&#39;fcgi-devel&#39;</span><span class="p">:</span> <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="n">installed</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># turn on avahi so we can do things like  &quot;ssh ceph00.local&quot; between the vm&#39;s</span>
</span><span class='line'>  <span class="kp">include</span> <span class="n">avahi</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># take the vagrant key for now and use it for passwordless ssh configs</span>
</span><span class='line'>        <span class="n">ssh_authorized_key</span> <span class="p">{</span> <span class="s2">&quot;root&quot;</span><span class="p">:</span>
</span><span class='line'>                <span class="k">ensure</span> <span class="o">=&gt;</span> <span class="s2">&quot;present&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">type</span> <span class="o">=&gt;</span> <span class="s2">&quot;ssh-rsa&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">key</span> <span class="o">=&gt;</span> <span class="s2">&quot;AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ==&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="nb">name</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant insecure public key&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">user</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/root/.ssh/id_rsa&quot;</span><span class="p">:</span>
</span><span class='line'>                <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_private_key&quot;</span> <span class="p">,</span>
</span><span class='line'>                <span class="nb">require</span> <span class="o">=&gt;</span> <span class="no">Ssh_authorized_key</span><span class="o">[</span><span class="s2">&quot;root&quot;</span><span class="o">]</span><span class="p">,</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/root/.ssh/config&quot;</span><span class="p">:</span>
</span><span class='line'>                <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;root&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_config&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="nb">require</span> <span class="o">=&gt;</span> <span class="no">Ssh_authorized_key</span><span class="o">[</span><span class="s2">&quot;root&quot;</span><span class="o">]</span><span class="p">,</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># the follow is done so the vagrant user can be used for testing and development without needing to su to the cephuser account</span>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/home/vagrant/.ssh/id_rsa&quot;</span><span class="p">:</span>
</span><span class='line'>      <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_private_key&quot;</span> <span class="p">,</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span> <span class="s2">&quot;/home/vagrant/.ssh/config&quot;</span><span class="p">:</span>
</span><span class='line'>      <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s2">&quot;0600&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">owner</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">group</span> <span class="o">=&gt;</span> <span class="s2">&quot;vagrant&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;puppet:///modules/insecure-keys/insecure_config&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># define the hosts in /etc/hosts</span>
</span><span class='line'>  <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph00&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.130&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph00&#39;</span><span class="p">,</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph01&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.131&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph01&#39;</span><span class="p">,</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">host</span> <span class="p">{</span> <span class="s1">&#39;ceph02&#39;</span><span class="p">:</span> <span class="n">ip</span> <span class="o">=&gt;</span> <span class="s1">&#39;10.0.1.132&#39;</span><span class="p">,</span> <span class="n">host_aliases</span> <span class="o">=&gt;</span> <span class="s1">&#39;ceph02&#39;</span><span class="p">,</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># disable selinux</span>
</span><span class='line'>  <span class="k">class</span> <span class="p">{</span> <span class="s1">&#39;selinux&#39;</span><span class="p">:</span>
</span><span class='line'>      <span class="n">mode</span> <span class="o">=&gt;</span> <span class="s1">&#39;disabled&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here&#8217;s also a sample <em>Vagrantfile</em> to get one started</p>

<figure class='code'><figcaption><span>Vagrantfile </span></figcaption><div class='highlight'><table><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># -*- mode: ruby -*-</span>
</span><span class='line'><span class="c1"># vi: set ft=ruby :</span>
</span><span class='line'>
</span><span class='line'><span class="c1">#</span>
</span><span class='line'><span class="c1"># For vagrant configuration options please go to http://vagrantup.com/v1/docs/index.html</span>
</span><span class='line'><span class="c1">#</span>
</span><span class='line'>
</span><span class='line'><span class="no">Vagrant</span><span class="o">::</span><span class="no">Config</span><span class="o">.</span><span class="n">run</span> <span class="k">do</span> <span class="o">|</span><span class="n">global_config</span><span class="o">|</span>
</span><span class='line'>  <span class="c1"># All Vagrant configuration is done here. The most common configuration</span>
</span><span class='line'>  <span class="c1"># options are documented and commented below. For a complete reference,</span>
</span><span class='line'>  <span class="c1"># please see the online documentation at vagrantup.com.</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># Every Vagrant virtual environment requires a box to build off of.</span>
</span><span class='line'>  <span class="c1"># We default to using SL which is a RHEL clone</span>
</span><span class='line'>  <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">box</span> <span class="o">=</span> <span class="s2">&quot;sl63-x86_64&quot;</span>
</span><span class='line'>  <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">box_url</span> <span class="o">=</span> <span class="s2">&quot;http://thammuz.tchpc.tcd.ie/mirrors/boxes/scientificlinux-6.3-x86_64-netboot-devops.box&quot;</span>
</span><span class='line'>  <span class="n">cephServers</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="nb">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">|</span>
</span><span class='line'>    <span class="n">global_config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">define</span> <span class="nb">name</span> <span class="k">do</span> <span class="o">|</span><span class="n">ceph</span><span class="o">|</span>
</span><span class='line'>      <span class="c1"># uncomment the following line if you want the basebox to start in gui mode</span>
</span><span class='line'>      <span class="c1">#ceph.vm.boot_mode = :gui</span>
</span><span class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">network</span> <span class="ss">:hostonly</span><span class="p">,</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:network</span><span class="o">]</span>
</span><span class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">host_name</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:host_name</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">provision</span> <span class="ss">:puppet</span><span class="p">,</span> <span class="ss">:facter</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;ceph_node_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;ceph@</span><span class="si">#{</span><span class="n">opts</span><span class="o">[</span><span class="ss">:network</span><span class="o">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="p">}</span> <span class="k">do</span> <span class="o">|</span><span class="n">puppet</span><span class="o">|</span>
</span><span class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">manifest_file</span> <span class="o">=</span> <span class="s2">&quot;site.pp&quot;</span>
</span><span class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">manifests_path</span> <span class="o">=</span> <span class="s1">&#39;puppet/manifests&#39;</span>
</span><span class='line'>        <span class="n">puppet</span><span class="o">.</span><span class="n">module_path</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;puppet/modules&#39;</span><span class="p">,</span> <span class="s1">&#39;puppet/services&#39;</span><span class="o">]</span>
</span><span class='line'>        <span class="c1">#puppet.options = &quot;--verbose --debug&quot;</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">ceph</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">customize</span> <span class="o">[</span>
</span><span class='line'>      <span class="s2">&quot;modifyvm&quot;</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span>
</span><span class='line'>      <span class="s2">&quot;--name&quot;</span><span class="p">,</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:host_name</span><span class="o">]</span><span class="p">,</span>
</span><span class='line'>      <span class="s2">&quot;--memory&quot;</span><span class="p">,</span> <span class="s2">&quot;1024&quot;</span>
</span><span class='line'>    <span class="o">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>With the Virtual Machines I was able to download the latest <a href="http://www.ceph.com/download/ceph-0.51.tar.bz2">Ceph
0.51</a> and do at least
the following</p>

<ul>
<li>unpack the tarball</li>
<li>do a <em>./configure</em> to generate the <em>ceph.spec</em> file</li>
<li>copy (or move) the ceph tarball into ~/rpmbuild/SOURCES</li>
<li>execute a <em>rpmbuild -ba ceph.spec</em> to build the source and binary rpm packages for installation</li>
</ul>


<p>After the RPM&#8217;s were built and installed, I again followed the quick
guide at <a href="http://ceph.com/docs/master/start/quick-start/">http://ceph.com/docs/master/start/quick-start/</a> and was able
to setup a small 3 node cluster for playing around with.</p>

<p>So to note, I tried out the cephfs feature (via the fuse module) and
creating(destroying and resizing) RBD&#8217;s. I haven&#8217;t had a chance to
experiment with the kernel modules to actually do something useful with
the POSIX filesystem or RBD&#8217;s that Ceph provides.</p>

<p>It would be worth nothing that the Ceph project are working on providing
prebuilt RPM&#8217;s soon, there is already a <a href="http://ceph.com/gitbuilder-centos6-rpm-amd64/">gitbuilder instance for the rpm
build</a> or just go to their
<a href="http://ceph.com/gitbuilder.cgi">gitbuilder aggregator</a></p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/02/scientific-linux-6-build-environment-for-ceph/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[RCE 62: Ceph Petabyte Scale Storage &rarr;]]></title>
<link href="http://www.rce-cast.com/Podcast/rce-62-ceph-petabyte-scale-storage.html"/>
<updated>2012-09-01T19:42:00-04:00</updated>
<id>http://jcftang.github.com/2012/09/01/rce-62-ceph-petabyte-scale-storage</id>

      <content type="html"><![CDATA[<p>It&#8217;s somewhat interesting to listen to, we&#8217;ve been looking at
<a href="http://www.ceph.com/">ceph</a> for a few things in work.</p>

<p>Just jotting this down so I remember to share this with the guys in work.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/09/01/rce-62-ceph-petabyte-scale-storage/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Taking Vagrant and running with it]]></title>
<link href="http://jcftang.github.com/2012/08/28/taking-vagrant-and-running-with-it/"/>
<updated>2012-08-28T18:49:00-04:00</updated>
<id>http://jcftang.github.com/2012/08/28/taking-vagrant-and-running-with-it</id>

      <content type="html"><![CDATA[<p>Over past few weeks I&#8217;ve been working on doing some integration and
testing work to try and deliver a prototype system. I&#8217;ve taken the
<a href="http://vagrantup.com/">Vagrant</a> tool and puppet to try and deliver
systems for testing and development. Although the systems that I am
currently working with aren&#8217;t fully automated, they are automated
enough for them to be easily started up by a developer who reads the
documentation (I hope).</p>

<p>I&#8217;m hoping that by providing these disposable systems that the various
members in the team that I am working with will be more free to experiment
and less fearful of breaking the system. At best everyone will take the
idea on board and run with it as it does provide a common environment
for all members in the team and it encourages reproducibility of issues
and features.</p>

<p>One of the next steps of building up the development framework that I
now have is to introduce some of these concepts and the whole Vagrant
environment to the more front facing part of the team who need to deal
with stakeholders in the project. If our requirements and policy team have
constant up to date access to our development, testing and QA environment
along with the executable specifications (in the form of cucumber tests)
I hope to push forward communications between the stakeholders and the
team that I&#8217;m working with.</p>

<p>For now I have one VM for the application itself and a number of
&#8220;clusters&#8221; of VM&#8217;s which I had used for reviewing some technical
documentation, they are partially automated for others to
play with. Currently these scripts are internal to the project
only, but it&#8217;s not hard to setup if you know how to configure
<a href="http://puppetlabs.com/">puppet</a>. Some of the scripts and ideas can
be found at <a href="https://github.com/jcftang/tchpc-vagrant">tchpc-vagrant</a>,
they&#8217;re not great, but not bad either. I need more of the developers in
the team to use what I&#8217;ve setup to evolve the system more for our use.</p>

<p>In parallel to using this for my day job, I&#8217;ve
also setup a Vagrantfile for one of my pet projects
<a href="https://github.com/jcftang/cports">cports</a>. Using Vagrant for testing
builds and deployments of a packaging system has been great. I&#8217;ve been
able to do clean rebuilds of various packages without fear of completely
polluting the enviroment, as its just a few commands away from being
redeployed and provisioned. I&#8217;ll need to play more and then release it
to the HPC community (or those that care).</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/08/28/taking-vagrant-and-running-with-it/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[An excuse to learn Ruby and Ruby on Rails]]></title>
<link href="http://jcftang.github.com/2012/08/02/an-excuse-to-learn-ruby-and-ruby-on-rails/"/>
<updated>2012-08-02T18:15:00-04:00</updated>
<id>http://jcftang.github.com/2012/08/02/an-excuse-to-learn-ruby-and-ruby-on-rails</id>

      <content type="html"><![CDATA[<p>I&#8217;ve been a long time consumer of ruby applications but never quite
got around to learning the language and the frameworks that are
available to developers. Within the team that I have been working
with, we&#8217;ve been evaluating <a href="http://projecthydra.org">hydra</a> as a
possible framework for our project.</p>

<p>I&#8217;ve been spending the last few days reading
<a href="http://pragprog.com/book/achbd/the-rspec-book">The RSpec Book</a>, I&#8217;ve
been able to pick up some of the basic syntax of the language from the
BDD book. As soon as I finish this book I will be moving on to a more
real world book relating to ruby with the goal of being able to
develop Ruby and Ruby on Rails applications.</p>

<p>Well, I didn&#8217;t get as far as finishing the RSpec book and I&#8217;ve started
creating a rubygem. I&#8217;m attempting to expose the insides of
<a href="https://tahoe-lafs.org/trac/zfec/">zfec</a>, specifically the
functionality in <em>fec.c</em>. So far I&#8217;ve been lazy and I am using swig to
automatically generate the C to ruby bindings with something like this</p>

<figure class='code'><figcaption><span>fec.i </span></figcaption><div class='highlight'><table><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="o">%</span><span class="n">module</span> <span class="n">fec</span>
</span><span class='line'>
</span><span class='line'><span class="o">%</span><span class="p">{</span>
</span><span class='line'><span class="cp">#include &quot;fec.h&quot;</span>
</span><span class='line'><span class="o">%</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">fec_t</span><span class="o">*</span> <span class="n">fec_new</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">k</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">m</span><span class="p">);</span>
</span><span class='line'><span class="kt">void</span> <span class="n">fec_free</span><span class="p">(</span><span class="n">fec_t</span><span class="o">*</span> <span class="n">p</span><span class="p">);</span>
</span><span class='line'><span class="kt">void</span> <span class="n">fec_decode</span><span class="p">(</span><span class="k">const</span> <span class="n">fec_t</span><span class="o">*</span> <span class="n">code</span><span class="p">,</span> <span class="k">const</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">inpkts</span><span class="p">,</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">outpkts</span><span class="p">,</span> <span class="k">const</span> <span class="kt">unsigned</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">index</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">sz</span><span class="p">);</span>
</span><span class='line'><span class="kt">void</span> <span class="n">fec_encode</span><span class="p">(</span><span class="k">const</span> <span class="n">fec_t</span><span class="o">*</span> <span class="n">code</span><span class="p">,</span> <span class="k">const</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">src</span><span class="p">,</span> <span class="n">gf</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">fecs</span><span class="p">,</span> <span class="k">const</span> <span class="kt">unsigned</span><span class="o">*</span><span class="kr">restrict</span> <span class="k">const</span> <span class="n">block_nums</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">num_block_nums</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">sz</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Swig does it&#8217;s thing,</p>

<figure class='code'><div class='highlight'><table><td class='gutter'><pre class='line-numbers'><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>swig -ruby fec.i
</span></code></pre></td></tr></table></div></figure>


<p>Amazingly after some fiddling I got ruby to load up the module. It
doesn&#8217;t mean that it&#8217;s going to do much though as I need to learn
about the typemaps in the ruby C interface do the correct mappings.</p>

<p>I&#8217;m so far taking inspiration from the zfec python module to take a
stab at building a ruby equivalent package for the sake of learning
ruby and maybe even end up with something useful for the project that
I am working on in work.</p>

<p>After playing with extending ruby, I&#8217;m thinking I may need to take a
step back and evaluate if this is the best way for me to learn ruby or
not. I should probably not mess too much extending the language with a
C library.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/08/02/an-excuse-to-learn-ruby-and-ruby-on-rails/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[OSX Kernel panics and VirtualBox]]></title>
<link href="http://jcftang.github.com/2012/07/20/osx-kernel-panics-and-virtualbox/"/>
<updated>2012-07-20T20:49:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/20/osx-kernel-panics-and-virtualbox</id>

      <content type="html"><![CDATA[<p>Having discovered <a href="http://vagrantup.com/">vagrant</a> and
<a href="https://github.com/jedi4ever/veewee">veewee</a> recently at OR2012 I&#8217;ve
been building a few <em>boxes</em> for our site for testing purposes. I&#8217;ve
had to relearn puppet to provision machines, but it&#8217;s paying off. I&#8217;ve
been able to deploy 3-4 virtual machines with relative ease.</p>

<p>The only disappointment is the seemingly frequent and semi-random
kernel panics and crashes that I get on OSX (which is probably caused
by VirtualBox when I do lots of IO). It&#8217;s making me rethink if I
really want to stick with OSX as my primary desktop OS in work. I may
have to revert back to using Linux at somepoint.</p>

<p>At least in Linux I know how to get a kdump out and debug the issue
but with OSX I&#8217;m not sure where I should begin to figure out what&#8217;s
broken.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/20/osx-kernel-panics-and-virtualbox/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Vagrant and Veewee for managing virtual machines for development]]></title>
<link href="http://jcftang.github.com/2012/07/17/vagrant-and-veewee-for-managing-virtual-machines-for-development/"/>
<updated>2012-07-17T12:06:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/17/vagrant-and-veewee-for-managing-virtual-machines-for-development</id>

      <content type="html"><![CDATA[<p>I only discovered <a href="https://github.com/mitchellh/vagrant">Vagrant</a> last
week at OR2012 when one of the presentations had Vagrant as a part of
the testing component in the project. I was pleasantly surprised that
it was leaveraging lots of free and opensource technology to provide
repeatable environments for development and testing. I was even more
impressed by the <a href="https://github.com/jedi4ever/veewee">Veewee</a> project
which provides some additional wrappers for building custom
&#8216;boxes&#8217;. Veewee certainly saved me lots of time in setting up some
updated <a href="http://www.scientificlinux.org/">Scientific Linux</a> boxes
(it&#8217;s my preferred distro for deployments).</p>

<p>In summary Vagrant is a set of scripts to manage virtual machines and
Veewee is a set of scripts for creating base images for use in
Vagrant. If you&#8217;re interested in the updated SL6.2 definitions they
can be found at my
<a href="https://github.com/jcftang/veewee/tree/scientificlinux-6.2">fork of veewee</a>.</p>

<p>All that is left now is to setup <a href="http://puppetlabs.com/">puppet</a> and
have it automatically provision my development/test environment. I&#8217;m
not a huge fan of puppet, but I guess it&#8217;s better than rolling my own.</p>

<p>I look forward to have the capability of having easy access to
disposable VM&#8217;s for prototyping and testing! I will need to at
somepoint setup a test system for cports with this tool.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/17/vagrant-and-veewee-for-managing-virtual-machines-for-development/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Open Repositories 2012 - the other days]]></title>
<link href="http://jcftang.github.com/2012/07/15/open-repositories-2012-the-other-days/"/>
<updated>2012-07-15T14:46:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/15/open-repositories-2012-the-other-days</id>

      <content type="html"><![CDATA[<p>I finally had gotten back from the conference late in the evening on
Friday, airport security was not fun at all. It was the first Open
Repositories conference that I had attended, the community seems to be
pretty tightly knit. There were two or three software stacks which
were presented that looked useful.  Things such as Fedora-Commons,
Hydra and a few other sub-components which were talked about are going
to be likely building blocks that we will be using for our Digital
Repository.</p>

<p>There was also a developer challenge which I decided to enter at the
last minute, it was both a new and interesting experience at
presenting something that wasn&#8217;t well prepared to an audience that I
had no experience with either. By the way, I was a team of one! I had
proposed the idea that replicating data can be expensive and bad,
there are alternatives to just copying files around en-mass and
storing replicas left right and centre.</p>

<p>I promised I would post some photos, but it seems my photos aren&#8217;t as
interesting as the ones that other people took. See
<a href="http://www.flickr.com/groups/or2012/">http://www.flickr.com/groups/or2012/</a>.</p>

<p>Next year Open Repositories will be held in Prince Edward Island,
Canada. I will need to be better prepared next year (assuming I go).</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/15/open-repositories-2012-the-other-days/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Open Repositories 2012 - Day 1 &rarr;]]></title>
<link href="http://or2012.ed.ac.uk/"/>
<updated>2012-07-09T20:04:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/09/open-repositories-2012-day-1</id>

      <content type="html"><![CDATA[<p>I only been here for a day and Edinburgh is as nice as I recall it
was. This time my attendance to Open Repositories 2012 brought me and
some co-workers of the DRI team to this city. It&#8217;s my first time at
this event and there seems to be lots of people, so far it&#8217;s been
pleasant enough apart from the weather.</p>

<p>For those interested in whats happening you should follow the hashtag
<strong><em>#or2012</em></strong> on twitter to see what people are saying. One of the cool
thing was they gave out 8gb USB memory sticks (built into the name
cards), I thought that was a nice touch.</p>

<p>So far it&#8217;s two thumbs up for the organisers. It&#8217;s only workshops for
far, I look forward to the poster sessions and other talks which will
be on. Day 2 will be more workshops and poster sessions, plus a
keynote.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/09/open-repositories-2012-day-1/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Installing Ceph on SL6]]></title>
<link href="http://jcftang.github.com/2012/07/06/installing-ceph-on-sl6/"/>
<updated>2012-07-06T14:43:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/06/installing-ceph-on-sl6</id>

      <content type="html"><![CDATA[<p>As an exercise of a Friday afternoon of not starting something big before
heading off to a conference. I&#8217;ve decided to spend an hour or two at
seeing how ceph is installed and configured on an SL6 based machine
(RHEL6 clone).</p>

<p>The install target is just an old desktop running a 64bit install of SL6x,
so it&#8217;s nothing too fancy.</p>

<p>Following the instructions at <a href="http://ceph.com/wiki/Installing_on_RedHat_or_CentOS">http://ceph.com/wiki/Installing_on_RedHat_or_CentOS</a>, I ended up doing this</p>

<pre><code>yum install yum-conf-epel
yum update
yum gcc gcc-c++ automake libtool expat expat-devel boost-devel nss-devel cryptopp cryptopp-devel libatomic_ops-devel fuse-devel
yum install libedit-devel libedit
</code></pre>

<p>It seems that the packages <em>cryptopp-devel</em>, <em>cryptopp</em> and <em>expat-devel</em>,
<em>expat</em> are the only packages pulled in from the epel repository.</p>

<p>Additional libraries and tools include these weren&#8217;t mentioned in the
upstream wiki, the upstream wiki probably needs to be updated.</p>

<pre><code>yum install rpm-build
yum install libaio-devel libcurl-devel libxml2-devel libuuid-devel keyutils-libs-devel fcgi-devel
</code></pre>

<p>I chose to install the newly designated stable branch of ceph 0.48argonaut</p>

<pre><code>wget http://ceph.com/download/ceph-0.48argonaut.tar.bz2
</code></pre>

<p>I also chose to build it in RPM form, in the tarball there is a RPM spec
file which can be used to create an installable RPM, the following is
a transcript of what I did to build an installable RPM.</p>

<pre><code>tar xjvf ceph-0.48argonaut.tar.bz2
cp ceph-0.48argonaut.tar.bz2 ~/rpmbuild/SOURCES
rpmbuild -ba ceph-0.48argonaut/ceph.spec
</code></pre>

<p>The build will take <em>some</em> time, especially if you are using old
hardware. I ran into some minor packaging issues,</p>

<pre><code>diff -u ceph.spec.in.orig ceph.spec.in
--- ceph.spec.in.orig   2012-07-06 15:38:59.298497719 +0100
+++ ceph.spec.in    2012-07-06 15:39:45.423560177 +0100
@@ -326,6 +326,8 @@
/usr/sbin/rcceph
%{_libdir}/rados-classes/libcls_rbd.so*
%{_libdir}/rados-classes/libcls_rgw.so*
+/sbin/ceph-disk-activate
+/sbin/ceph-disk-prepare

#################################################################################
%files fuse
</code></pre>

<p>The above change need&#8217;s to be applied to the <em>ceph</em> spec file for the
RPM(s) to build successfully.</p>

<pre><code>ceph-0.48argonaut-6.el6.x86_64.rpm
ceph-devel-0.48argonaut-6.el6.x86_64.rpm
python-ceph-0.48argonaut-6.el6.x86_64.rpm
librbd1-0.48argonaut-6.el6.x86_64.rpm
librados2-0.48argonaut-6.el6.x86_64.rpm
ceph-radosgw-0.48argonaut-6.el6.x86_64.rpm
libcephfs1-0.48argonaut-6.el6.x86_64.rpm
ceph-fuse-0.48argonaut-6.el6.x86_64.rpm
</code></pre>

<p>I chose to install <em>all</em> the RPM&#8217;s that were generated for educational
purposes (used yum instead of the rpm commands so the dependancies are
sorted out for me), from the <em>rpmbuild/RPMS/x86_64</em> directory</p>

<pre><code>yum install ceph-0.48argonaut-6.el6.x86_64.rpm ceph-devel-0.48argonaut-6.el6.x86_64.rpm ceph-fuse-0.48argonaut-6.el6.x86_64.rpm ceph-radosgw-0.48argonaut-6.el6.x86_64.rpm libcephfs1-0.48argonaut-6.el6.x86_64.rpm librados2-0.48argonaut-6.el6.x86_64.rpm librbd1-0.48argonaut-6.el6.x86_64.rpm python-ceph-0.48argonaut-6.el6.x86_64.rpm
</code></pre>

<p>I then simply followed the 5 minute quick start guide at
<a href="http://ceph.com/docs/master/start/quick-start/">http://ceph.com/docs/master/start/quick-start/</a> to see if ceph would
start up. There is more documentation at <a href="http://ceph.com/docs/master">http://ceph.com/docs/master</a>
that I have yet to go through. Perhaps the configuration of ceph can go
into another post.</p>

<p>To start the cluster after it&#8217;s configured</p>

<pre><code>service ceph -a start
</code></pre>

<p>However on my test system it&#8217;s currently crashing out with the mds server giving the followin errors</p>

<pre><code>2012-07-06 16:38:17.838055 7f2d6828d700 -1 mds.-1.0 *** got signal Terminated ***
2012-07-06 16:38:17.838139 7f2d6828d700  1 mds.-1.0 suicide.  wanted down:dne, now up:boot
2012-07-06 16:38:17.839020 7f2d6828d700 -1 osdc/Objecter.cc: In function 'void Objecter::shutdown()' thread 7f2d6828d700 time 2012-07-06 16:38:17.838156
osdc/Objecter.cc: 221: FAILED assert(initialized)

 ceph version 0.48argonaut (commit:c2b20ca74249892c8e5e40c12aa14446a2bf2030)
 1: (Objecter::shutdown()+0x170) [0x6e2e20]
 2: (MDS::suicide()+0xc9) [0x4ad829]
 3: (MDS::handle_signal(int)+0x1bb) [0x4b447b]
 4: (SignalHandler::entry()+0x283) [0x803d53]
 5: /lib64/libpthread.so.0() [0x3b3ea077f1]
 6: (clone()+0x6d) [0x3b3e6e5ccd]
 NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.

--- begin dump of recent events ---
    -3&gt; 2012-07-06 16:37:57.786954 7f2d6b496760  0 ceph version 0.48argonaut (commit:c2b20ca74249892c8e5e40c12aa14446a2bf2030), process ceph-mds, pid 12537
    -2&gt; 2012-07-06 16:38:17.838055 7f2d6828d700 -1 mds.-1.0 *** got signal Terminated ***
    -1&gt; 2012-07-06 16:38:17.838139 7f2d6828d700  1 mds.-1.0 suicide.  wanted down:dne, now up:boot
     0&gt; 2012-07-06 16:38:17.839020 7f2d6828d700 -1 osdc/Objecter.cc: In function 'void Objecter::shutdown()' thread 7f2d6828d700 time 2012-07-06 16:38:17.838156
osdc/Objecter.cc: 221: FAILED assert(initialized)

 ceph version 0.48argonaut (commit:c2b20ca74249892c8e5e40c12aa14446a2bf2030)
 1: (Objecter::shutdown()+0x170) [0x6e2e20]
 2: (MDS::suicide()+0xc9) [0x4ad829]
 3: (MDS::handle_signal(int)+0x1bb) [0x4b447b]
 4: (SignalHandler::entry()+0x283) [0x803d53]
 5: /lib64/libpthread.so.0() [0x3b3ea077f1]
 6: (clone()+0x6d) [0x3b3e6e5ccd]
 NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.

--- end dump of recent events ---
2012-07-06 16:38:17.840237 7f2d6828d700 -1 *** Caught signal (Aborted) **
 in thread 7f2d6828d700

 ceph version 0.48argonaut (commit:c2b20ca74249892c8e5e40c12aa14446a2bf2030)
 1: /usr/bin/ceph-mds() [0x803309]
 2: /lib64/libpthread.so.0() [0x3b3ea0f4a0]
 3: (gsignal()+0x35) [0x3b3e632885]
 4: (abort()+0x175) [0x3b3e634065]
 5: (__gnu_cxx::__verbose_terminate_handler()+0x12d) [0x3b432bea7d]
 NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.

--- begin dump of recent events ---
     0&gt; 2012-07-06 16:38:17.840237 7f2d6828d700 -1 *** Caught signal (Aborted) **
 in thread 7f2d6828d700

 ceph version 0.48argonaut (commit:c2b20ca74249892c8e5e40c12aa14446a2bf2030)
 1: /usr/bin/ceph-mds() [0x803309]
 2: /lib64/libpthread.so.0() [0x3b3ea0f4a0]
 3: (gsignal()+0x35) [0x3b3e632885]
 4: (abort()+0x175) [0x3b3e634065]
 5: (__gnu_cxx::__verbose_terminate_handler()+0x12d) [0x3b432bea7d]
 NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.

--- end dump of recent events ---
</code></pre>

<p>I&#8217;ve logged the error message on the ceph-devel mailing list, I don&#8217;t
have time to poke at this problem right now. I need to recreate this
scenario in a VM on my laptop so I can play with this on the plane when
I&#8217;m going to Open Repositories 2012 this weekend.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/06/installing-ceph-on-sl6/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Thoughts on using the likes of tahoe-lafs and git-annex as a backend storage system for Digital Preservation]]></title>
<link href="http://jcftang.github.com/2012/07/05/thoughts-on-using-the-likes-of-tahoe-lafs-and-git-annex-as-a-backend-storage-system-for-digital-preservation/"/>
<updated>2012-07-05T15:29:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/05/thoughts-on-using-the-likes-of-tahoe-lafs-and-git-annex-as-a-backend-storage-system-for-digital-preservation</id>

      <content type="html"><![CDATA[<p>Having happily running and using both git-annex and tahoe-lafs in the
past year or so to manage my files and backups. I&#8217;ve been thinking
about plugging in tahoe-lafs as a backend driver for iRODS. I never
quite got around to doing it properly, I had only gotten the universal
mass storage driver to talk to tahoe-lafs. I was planning on writing
an MSO driver for iRODS to talk to tahoe-lafs&#8217;s web-api, but alas I
never got around to it. I need to get some interns to do it next year!</p>

<p>It&#8217;s still highly attractive to have tahoe-lafs at the storage backend
due to its erasure coding capabilities to maximise a return on
investment in the storage infrastructure. I&#8217;m not sure if anyone has
really tried to use something like tahoe-lafs as a backend for digital
preservation.</p>

<p>There are a few niggling issues with tahoe-lafs which may prevent one
from using it in digital preservation, one is the lack of
precedence. Someone needs to take a first step at trying to see if it
works or not. Personally I would like to see the multi-introducer work
to be production ready and released, this would hugely increase the
availability of a tahoe-lafs grid and would mitigate the need for
trying make one introducer node highly available and redundant and of
course local network performance could be better. I&#8217;ve never really
been able to get more than 10-20mbit/s out of a download/upload. If my
transfers are queued up and running in the background it&#8217;s not a major
issue.</p>

<p>Which brings me to git-annex, all the new fancy features that the
author of git-annex has been adding has been fantastic. I&#8217;ve setup a
&#8220;target&#8221; which is a tahoe-lafs grid which I use a replica set for one
of my annex&#8217;d collection of files. It&#8217;s not the fastest thing in the
world for transfers but at least I know my data is safe in at least
two places.</p>

<p>Having used git-annex happily for the past while and being interested
in the S3 and SWIFT interfaces that git-annex is able to talk to has
made me wonder if it&#8217;s a good idea to try and create a fedora-commons
backend/remote for git-annex or a real tahoe-lafs backend/remote that
doesn&#8217;t rely on the general hook system that git-annex already
has. Also the Internet Archive provides an S3/SWIFT like interface.</p>

<p>Or would it be better to go the other way around and try using
git-annex as a type of interface to other backend storage systems for
fedora-commons, I wish I had more time to poke the akubra
interface/package in fedora-commons.</p>

<p>The above is just a rant and my brain spewing random stuff out in the
afternoon after thinking about the OR2012 developer challenge.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/05/thoughts-on-using-the-likes-of-tahoe-lafs-and-git-annex-as-a-backend-storage-system-for-digital-preservation/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[Ceph V0.48 ARGONAUT RELEASED &rarr;]]></title>
<link href="http://ceph.com/releases/v0-48-argonaut-released/"/>
<updated>2012-07-05T09:54:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/05/ceph-v0-dot-48-argonaut-released</id>

      <content type="html"><![CDATA[<p>I&#8217;ve been eyeing this Ceph storage system for a while for a number of
potential uses, it looks like its finally ready for production usage.</p>

<p>It is a pitty that the cephfs component isn&#8217;t recommended for
production usage yet. Still, Ceph is really going to shake up the
distributed storage industry. Having used GPFS, Lustre and a few other
systems in production in the past, Ceph certainly looks attractive.</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/05/ceph-v0-dot-48-argonaut-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
    <entry>
      




<title type="html"><![CDATA[tahoe-lafs 1.9.2 is released &rarr;]]></title>
<link href="https://tahoe-lafs.org/trac/tahoe-lafs/wiki/Installation"/>
<updated>2012-07-05T09:47:00-04:00</updated>
<id>http://jcftang.github.com/2012/07/05/tahoe-lafs-1-dot-9-2-is-released</id>

      <content type="html"><![CDATA[<p>I&#8217;ve been happily using <a href="http://www.tahoe-lafs.org">tahoe-lafs</a> for my
backup needs for a while now in work. It&#8217;s not a huge cluster, but just
a small hive cache from workstations dotted around the lab.</p>

<p>The project recently did a release which fixes a number of bugs and
issues which has made this software much more pleasant to use. I&#8217;ve
also been happily using git-annex to manage my files which reside in
tahoe-lafs.</p>

<p>At somepoint I need to write a tahoe-lafs backend/remote for git-annex,
or at least convince the git-annex author to write one!</p>
<p><a rel="bookmark" href="http://jcftang.github.com/2012/07/05/tahoe-lafs-1-dot-9-2-is-released/">&#9875; Permalink</a></p>]]></content>
    </entry>
  
</feed>
